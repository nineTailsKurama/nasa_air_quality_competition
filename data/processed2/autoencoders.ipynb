{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3883d510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1378938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180308T031500_maiac_tpe_0.hdf.json    \u001b[34mAOD at 0.55 micron\u001b[m\u001b[m/\r\n",
      "20180308T031500_maiac_tpe_0.hdf.pickle  \u001b[34mPyTorch-VAE\u001b[m\u001b[m/\r\n",
      "\u001b[34mAOD at 0.47 micron\u001b[m\u001b[m/                     autoencoders.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cd4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "import glob\n",
    "al_55 = glob.glob(\"AOD at 0.55 micron/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "596beec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(al_55[0], 'rb') as handle:\n",
    "     b = pickle.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b391a6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-2c2fb2f3b858>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.array([ np.array(j[\"data\"]['AOD at 0.55 micron']) for j in b]).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([ np.array(j[\"data\"]['AOD at 0.55 micron']) for j in b]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "782072e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48efe7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(b[0][\"data\"]['AOD at 0.47 micron'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad95a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc_returnarr(i):\n",
    "    with open(i, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return np.array([ np.array(j[\"data\"]['AOD at 0.55 micron']) for j in b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5a13383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-5e135b70dd57>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array([ np.array(j[\"data\"]['AOD at 0.55 micron']) for j in b])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 s, sys: 14.8 s, total: 27.6 s\n",
      "Wall time: 1min 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-5e135b70dd57>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array([ np.array(j[\"data\"]['AOD at 0.55 micron']) for j in b])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-66:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/envs/cv/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/anaconda3/envs/cv/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/anaconda3/envs/cv/lib/python3.8/multiprocessing/pool.py\", line 131, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/opt/homebrew/anaconda3/envs/cv/lib/python3.8/multiprocessing/queues.py\", line 367, in put\n",
      "    with self._wlock:\n",
      "  File \"/opt/homebrew/anaconda3/envs/cv/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loc_returnarr(\"AOD at 0.55 micron/240.pickle\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdd8f7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(al_55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fdbac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]<ipython-input-7-5e135b70dd57>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array([ np.array(j[\"data\"]['AOD at 0.55 micron']) for j in b])\n",
      "<ipython-input-7-5e135b70dd57>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array([ np.array(j[\"data\"]['AOD at 0.55 micron']) for j in b])\n",
      "<ipython-input-7-5e135b70dd57>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array([ np.array(j[\"data\"]['AOD at 0.55 micron']) for j in b])\n",
      "<ipython-input-7-5e135b70dd57>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array([ np.array(j[\"data\"]['AOD at 0.55 micron']) for j in b])\n",
      "  4%|‚ñç         | 4/100 [06:16<2:30:47, 94.24s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/cv/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-304c8325afee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fork\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mall_files_d_100\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_returnarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mal_55\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mal_55\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mall_files_d_100\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/cv/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/cv/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    854\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/cv/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing import get_context\n",
    "import tqdm\n",
    "p = get_context(\"fork\").Pool(4)\n",
    "all_files_d_100 = []\n",
    "for x in tqdm.tqdm(p.imap_unordered(loc_returnarr, al_55[:100]), total=len(al_55[:100])):\n",
    "    all_files_d_100.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3b809e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6cd11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d551a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8418f5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f01fbb84",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-6b17c7868a31>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-6b17c7868a31>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    from \"PyTorch-VAE/models\" import BaseVAE\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from \"PyTorch-VAE/models\" import BaseVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f530d8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from .base import *\r\n",
      "from .vanilla_vae import *\r\n",
      "from .gamma_vae import *\r\n",
      "from .beta_vae import *\r\n",
      "from .wae_mmd import *\r\n",
      "from .cvae import *\r\n",
      "from .hvae import *\r\n",
      "from .vampvae import *\r\n",
      "from .iwae import *\r\n",
      "from .dfcvae import *\r\n",
      "from .mssim_vae import MSSIMVAE\r\n",
      "from .fvae import *\r\n",
      "from .cat_vae import *\r\n",
      "from .joint_vae import *\r\n",
      "from .info_vae import *\r\n",
      "# from .twostage_vae import *\r\n",
      "from .lvae import LVAE\r\n",
      "from .logcosh_vae import *\r\n",
      "from .swae import *\r\n",
      "from .miwae import *\r\n",
      "from .vq_vae import *\r\n",
      "from .betatc_vae import *\r\n",
      "from .dip_vae import *\r\n",
      "\r\n",
      "\r\n",
      "# Aliases\r\n",
      "VAE = VanillaVAE\r\n",
      "GaussianVAE = VanillaVAE\r\n",
      "CVAE = ConditionalVAE\r\n",
      "GumbelVAE = CategoricalVAE\r\n",
      "\r\n",
      "vae_models = {'HVAE':HVAE,\r\n",
      "              'LVAE':LVAE,\r\n",
      "              'IWAE':IWAE,\r\n",
      "              'SWAE':SWAE,\r\n",
      "              'MIWAE':MIWAE,\r\n",
      "              'VQVAE':VQVAE,\r\n",
      "              'DFCVAE':DFCVAE,\r\n",
      "              'DIPVAE':DIPVAE,\r\n",
      "              'BetaVAE':BetaVAE,\r\n",
      "              'InfoVAE':InfoVAE,\r\n",
      "              'WAE_MMD':WAE_MMD,\r\n",
      "              'VampVAE': VampVAE,\r\n",
      "              'GammaVAE':GammaVAE,\r\n",
      "              'MSSIMVAE':MSSIMVAE,\r\n",
      "              'JointVAE':JointVAE,\r\n",
      "              'BetaTCVAE':BetaTCVAE,\r\n",
      "              'FactorVAE':FactorVAE,\r\n",
      "              'LogCoshVAE':LogCoshVAE,\r\n",
      "              'VanillaVAE':VanillaVAE,\r\n",
      "              'ConditionalVAE':ConditionalVAE,\r\n",
      "              'CategoricalVAE':CategoricalVAE}\r\n"
     ]
    }
   ],
   "source": [
    "cat PyTorch-VAE/models/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83757573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import BaseVAE\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import BaseVAE\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from .types_ import *\n",
    "\n",
    "\n",
    "class InfoVAE(BaseVAE):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 latent_dim: int,\n",
    "                 hidden_dims: List = None,\n",
    "                 alpha: float = -0.5,\n",
    "                 beta: float = 5.0,\n",
    "                 reg_weight: int = 100,\n",
    "                 kernel_type: str = 'imq',\n",
    "                 latent_var: float = 2.,\n",
    "                 **kwargs) -> None:\n",
    "        super(InfoVAE, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.reg_weight = reg_weight\n",
    "        self.kernel_type = kernel_type\n",
    "        self.z_var = latent_var\n",
    "\n",
    "        assert alpha <= 0, 'alpha must be negative or zero.'\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "        modules = []\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 64, 128, 256, 512]\n",
    "\n",
    "        # Build Encoder\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels=h_dim,\n",
    "                              kernel_size= 3, stride= 2, padding  = 1),\n",
    "                    nn.BatchNorm2d(h_dim),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1] * 4, latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dims[-1] * 4, latent_dim)\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1] * 4)\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(hidden_dims[i],\n",
    "                                       hidden_dims[i + 1],\n",
    "                                       kernel_size=3,\n",
    "                                       stride = 2,\n",
    "                                       padding=1,\n",
    "                                       output_padding=1),\n",
    "                    nn.BatchNorm2d(hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(\n",
    "                            nn.ConvTranspose2d(hidden_dims[-1],\n",
    "                                               hidden_dims[-1],\n",
    "                                               kernel_size=3,\n",
    "                                               stride=2,\n",
    "                                               padding=1,\n",
    "                                               output_padding=1),\n",
    "                            nn.BatchNorm2d(hidden_dims[-1]),\n",
    "                            nn.LeakyReLU(),\n",
    "                            nn.Conv2d(hidden_dims[-1], out_channels= 3,\n",
    "                                      kernel_size= 3, padding= 1),\n",
    "                            nn.Tanh())\n",
    "\n",
    "    def encode(self, input: Tensor) -> List[Tensor]:\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mu = self.fc_mu(result)\n",
    "        log_var = self.fc_var(result)\n",
    "        return [mu, log_var]\n",
    "\n",
    "    def decode(self, z: Tensor) -> Tensor:\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, 512, 2, 2)\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "        return result\n",
    "\n",
    "    def reparameterize(self, mu: Tensor, logvar: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Reparameterization trick to sample from N(mu, var) from\n",
    "        N(0,1).\n",
    "        :param mu: (Tensor) Mean of the latent Gaussian [B x D]\n",
    "        :param logvar: (Tensor) Standard deviation of the latent Gaussian [B x D]\n",
    "        :return: (Tensor) [B x D]\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, input: Tensor, **kwargs) -> List[Tensor]:\n",
    "        mu, log_var = self.encode(input)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return  [self.decode(z), input, z, mu, log_var]\n",
    "\n",
    "    def loss_function(self,\n",
    "                      *args,\n",
    "                      **kwargs) -> dict:\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        z = args[2]\n",
    "        mu = args[3]\n",
    "        log_var = args[4]\n",
    "\n",
    "        batch_size = input.size(0)\n",
    "        bias_corr = batch_size *  (batch_size - 1)\n",
    "        kld_weight = kwargs['M_N']  # Account for the minibatch samples from the dataset\n",
    "\n",
    "        recons_loss =F.mse_loss(recons, input)\n",
    "        mmd_loss = self.compute_mmd(z)\n",
    "        kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim=1), dim=0)\n",
    "\n",
    "        loss = self.beta * recons_loss + \\\n",
    "               (1. - self.alpha) * kld_weight * kld_loss + \\\n",
    "               (self.alpha + self.reg_weight - 1.)/bias_corr * mmd_loss\n",
    "        return {'loss': loss, 'Reconstruction_Loss':recons_loss, 'MMD': mmd_loss, 'KLD':-kld_loss}\n",
    "\n",
    "    def compute_kernel(self,\n",
    "                       x1: Tensor,\n",
    "                       x2: Tensor) -> Tensor:\n",
    "        # Convert the tensors into row and column vectors\n",
    "        D = x1.size(1)\n",
    "        N = x1.size(0)\n",
    "\n",
    "        x1 = x1.unsqueeze(-2) # Make it into a column tensor\n",
    "        x2 = x2.unsqueeze(-3) # Make it into a row tensor\n",
    "\n",
    "        \"\"\"\n",
    "        Usually the below lines are not required, especially in our case,\n",
    "        but this is useful when x1 and x2 have different sizes\n",
    "        along the 0th dimension.\n",
    "        \"\"\"\n",
    "        x1 = x1.expand(N, N, D)\n",
    "        x2 = x2.expand(N, N, D)\n",
    "\n",
    "        if self.kernel_type == 'rbf':\n",
    "            result = self.compute_rbf(x1, x2)\n",
    "        elif self.kernel_type == 'imq':\n",
    "            result = self.compute_inv_mult_quad(x1, x2)\n",
    "        else:\n",
    "            raise ValueError('Undefined kernel type.')\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def compute_rbf(self,\n",
    "                    x1: Tensor,\n",
    "                    x2: Tensor,\n",
    "                    eps: float = 1e-7) -> Tensor:\n",
    "        \"\"\"\n",
    "        Computes the RBF Kernel between x1 and x2.\n",
    "        :param x1: (Tensor)\n",
    "        :param x2: (Tensor)\n",
    "        :param eps: (Float)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        z_dim = x2.size(-1)\n",
    "        sigma = 2. * z_dim * self.z_var\n",
    "\n",
    "        result = torch.exp(-((x1 - x2).pow(2).mean(-1) / sigma))\n",
    "        return result\n",
    "\n",
    "    def compute_inv_mult_quad(self,\n",
    "                               x1: Tensor,\n",
    "                               x2: Tensor,\n",
    "                               eps: float = 1e-7) -> Tensor:\n",
    "        \"\"\"\n",
    "        Computes the Inverse Multi-Quadratics Kernel between x1 and x2,\n",
    "        given by\n",
    "                k(x_1, x_2) = \\sum \\frac{C}{C + \\|x_1 - x_2 \\|^2}\n",
    "        :param x1: (Tensor)\n",
    "        :param x2: (Tensor)\n",
    "        :param eps: (Float)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        z_dim = x2.size(-1)\n",
    "        C = 2 * z_dim * self.z_var\n",
    "        kernel = C / (eps + C + (x1 - x2).pow(2).sum(dim = -1))\n",
    "\n",
    "        # Exclude diagonal elements\n",
    "        result = kernel.sum() - kernel.diag().sum()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def compute_mmd(self, z: Tensor) -> Tensor:\n",
    "        # Sample from prior (Gaussian) distribution\n",
    "        prior_z = torch.randn_like(z)\n",
    "\n",
    "        prior_z__kernel = self.compute_kernel(prior_z, prior_z)\n",
    "        z__kernel = self.compute_kernel(z, z)\n",
    "        priorz_z__kernel = self.compute_kernel(prior_z, z)\n",
    "\n",
    "        mmd = prior_z__kernel.mean() + \\\n",
    "              z__kernel.mean() - \\\n",
    "              2 * priorz_z__kernel.mean()\n",
    "        return mmd\n",
    "\n",
    "    def sample(self,\n",
    "               num_samples:int,\n",
    "               current_device: int, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the latent space and return the corresponding\n",
    "        image space map.\n",
    "        :param num_samples: (Int) Number of samples\n",
    "        :param current_device: (Int) Device to run the model\n",
    "        :return: (Tensor)\n",
    "        \"\"\"\n",
    "        z = torch.randn(num_samples,\n",
    "                        self.latent_dim)\n",
    "\n",
    "        z = z.to(current_device)\n",
    "\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "    def generate(self, x: Tensor, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Given an input image x, returns the reconstructed image\n",
    "        :param x: (Tensor) [B x C x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337459ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
