{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "433363ab",
   "metadata": {},
   "source": [
    "# Recurrent Network\n",
    "\n",
    "In this Notebook, we will do over Recurrent Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb706f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "# import dataset, network to train and metric to optimize\n",
    "from pytorch_forecasting import TimeSeriesDataSet, RecurrentNetwork, QuantileLoss\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss, RMSE\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76b0b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_forecasting.metrics.RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa2a9e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"scpppi/processed_data_l.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e82380fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_df(df):\n",
    "    df = df.drop(columns=[\"Unnamed: 0\",\"datetime\",\"granule_id\"])\n",
    "    df[\"datetime_dt\"] = pd.to_datetime(df[\"datetime_dt\"] )\n",
    "    df[\"month\"] = [i.month for i in df[\"datetime_dt\"]]\n",
    "    df[\"month\"] = df[\"month\"].astype(str).astype(\"category\")\n",
    "    one_hot = pd.get_dummies(df[\"month\"])\n",
    "    df = df.join(one_hot)\n",
    "    df = df.drop('month',axis = 1)\n",
    "    df = df.drop('date',axis = 1)\n",
    "#     one_hot = pd.get_dummies(df[\"location\"])\n",
    "#     df = df.join(one_hot)\n",
    "#     one_hot = pd.get_dummies(df[\"grid_id\"])\n",
    "#     df = df.join(one_hot)\n",
    "#     df = df.drop('grid_id',axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c096e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aca23a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_dt</th>\n",
       "      <th>location</th>\n",
       "      <th>AOD at 0.47 micron_0</th>\n",
       "      <th>AOD at 0.47 micron_1</th>\n",
       "      <th>AOD at 0.47 micron_2</th>\n",
       "      <th>AOD at 0.47 micron_3</th>\n",
       "      <th>AOD at 0.47 micron_4</th>\n",
       "      <th>AOD at 0.47 micron_5</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3S31A</td>\n",
       "      <td>11.4</td>\n",
       "      <td>2018-02-01 08:00:00+00:00</td>\n",
       "      <td>Los Angeles (SoCAB)</td>\n",
       "      <td>-0.563344</td>\n",
       "      <td>0.109907</td>\n",
       "      <td>-0.103034</td>\n",
       "      <td>0.234161</td>\n",
       "      <td>-0.041027</td>\n",
       "      <td>0.229606</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2FBI</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2018-02-01 08:00:00+00:00</td>\n",
       "      <td>Los Angeles (SoCAB)</td>\n",
       "      <td>-0.563344</td>\n",
       "      <td>0.109907</td>\n",
       "      <td>-0.103034</td>\n",
       "      <td>0.234161</td>\n",
       "      <td>-0.041027</td>\n",
       "      <td>0.229606</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DJN0F</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2018-02-01 08:00:00+00:00</td>\n",
       "      <td>Los Angeles (SoCAB)</td>\n",
       "      <td>-0.563344</td>\n",
       "      <td>0.109907</td>\n",
       "      <td>-0.103034</td>\n",
       "      <td>0.234161</td>\n",
       "      <td>-0.041027</td>\n",
       "      <td>0.229606</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E5P9N</td>\n",
       "      <td>22.1</td>\n",
       "      <td>2018-02-01 08:00:00+00:00</td>\n",
       "      <td>Los Angeles (SoCAB)</td>\n",
       "      <td>-0.563344</td>\n",
       "      <td>0.109907</td>\n",
       "      <td>-0.103034</td>\n",
       "      <td>0.234161</td>\n",
       "      <td>-0.041027</td>\n",
       "      <td>0.229606</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FRITQ</td>\n",
       "      <td>29.8</td>\n",
       "      <td>2018-02-01 08:00:00+00:00</td>\n",
       "      <td>Los Angeles (SoCAB)</td>\n",
       "      <td>-0.563344</td>\n",
       "      <td>0.109907</td>\n",
       "      <td>-0.103034</td>\n",
       "      <td>0.234161</td>\n",
       "      <td>-0.041027</td>\n",
       "      <td>0.229606</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2064 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  grid_id  value               datetime_dt             location  \\\n",
       "0   3S31A   11.4 2018-02-01 08:00:00+00:00  Los Angeles (SoCAB)   \n",
       "1   A2FBI   17.0 2018-02-01 08:00:00+00:00  Los Angeles (SoCAB)   \n",
       "2   DJN0F   11.1 2018-02-01 08:00:00+00:00  Los Angeles (SoCAB)   \n",
       "3   E5P9N   22.1 2018-02-01 08:00:00+00:00  Los Angeles (SoCAB)   \n",
       "4   FRITQ   29.8 2018-02-01 08:00:00+00:00  Los Angeles (SoCAB)   \n",
       "\n",
       "   AOD at 0.47 micron_0  AOD at 0.47 micron_1  AOD at 0.47 micron_2  \\\n",
       "0             -0.563344              0.109907             -0.103034   \n",
       "1             -0.563344              0.109907             -0.103034   \n",
       "2             -0.563344              0.109907             -0.103034   \n",
       "3             -0.563344              0.109907             -0.103034   \n",
       "4             -0.563344              0.109907             -0.103034   \n",
       "\n",
       "   AOD at 0.47 micron_3  AOD at 0.47 micron_4  AOD at 0.47 micron_5  ...  11  \\\n",
       "0              0.234161             -0.041027              0.229606  ...   0   \n",
       "1              0.234161             -0.041027              0.229606  ...   0   \n",
       "2              0.234161             -0.041027              0.229606  ...   0   \n",
       "3              0.234161             -0.041027              0.229606  ...   0   \n",
       "4              0.234161             -0.041027              0.229606  ...   0   \n",
       "\n",
       "   12  2  3  4  5  6  7  8  9  \n",
       "0   0  1  0  0  0  0  0  0  0  \n",
       "1   0  1  0  0  0  0  0  0  0  \n",
       "2   0  1  0  0  0  0  0  0  0  \n",
       "3   0  1  0  0  0  0  0  0  0  \n",
       "4   0  1  0  0  0  0  0  0  0  \n",
       "\n",
       "[5 rows x 2064 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ec4ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec4079a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"time_idx\"] = data[\"datetime_dt\"].dt.year * 365 + data[\"datetime_dt\"].dt.month *30 + data[\"datetime_dt\"].dt.day\n",
    "data[\"time_idx\"] -= data[\"time_idx\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20d0869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(\"time_idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9264c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 100\n",
    "max_encoder_length = 18\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e434096a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AOD at 0_47 micron_0', 'AOD at 0_47 micron_1']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_varying_known_reals = [i.replace(\".\",\"_\") for i in list(data.columns[4:])]\n",
    "time_varying_known_reals[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "419af854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AOD at 0_47 micron_0',\n",
       " 'AOD at 0_47 micron_1',\n",
       " 'AOD at 0_47 micron_2',\n",
       " 'AOD at 0_47 micron_3',\n",
       " 'AOD at 0_47 micron_4',\n",
       " 'AOD at 0_47 micron_5',\n",
       " 'AOD at 0_47 micron_6',\n",
       " 'AOD at 0_47 micron_7',\n",
       " 'AOD at 0_47 micron_8',\n",
       " 'AOD at 0_47 micron_9',\n",
       " 'AOD at 0_47 micron_10',\n",
       " 'AOD at 0_47 micron_11',\n",
       " 'AOD at 0_47 micron_12',\n",
       " 'AOD at 0_47 micron_13',\n",
       " 'AOD at 0_47 micron_14',\n",
       " 'AOD at 0_47 micron_15',\n",
       " 'AOD at 0_47 micron_16',\n",
       " 'AOD at 0_47 micron_17',\n",
       " 'AOD at 0_47 micron_18',\n",
       " 'AOD at 0_47 micron_19',\n",
       " 'AOD at 0_47 micron_20',\n",
       " 'AOD at 0_47 micron_21',\n",
       " 'AOD at 0_47 micron_22',\n",
       " 'AOD at 0_47 micron_23',\n",
       " 'AOD at 0_47 micron_24',\n",
       " 'AOD at 0_47 micron_25',\n",
       " 'AOD at 0_47 micron_26',\n",
       " 'AOD at 0_47 micron_27',\n",
       " 'AOD at 0_47 micron_28',\n",
       " 'AOD at 0_47 micron_29',\n",
       " 'AOD at 0_47 micron_30',\n",
       " 'AOD at 0_47 micron_31',\n",
       " 'AOD at 0_47 micron_32',\n",
       " 'AOD at 0_47 micron_33',\n",
       " 'AOD at 0_47 micron_34',\n",
       " 'AOD at 0_47 micron_35',\n",
       " 'AOD at 0_47 micron_36',\n",
       " 'AOD at 0_47 micron_37',\n",
       " 'AOD at 0_47 micron_38',\n",
       " 'AOD at 0_47 micron_39',\n",
       " 'AOD at 0_47 micron_40',\n",
       " 'AOD at 0_47 micron_41',\n",
       " 'AOD at 0_47 micron_42',\n",
       " 'AOD at 0_47 micron_43',\n",
       " 'AOD at 0_47 micron_44',\n",
       " 'AOD at 0_47 micron_45',\n",
       " 'AOD at 0_47 micron_46',\n",
       " 'AOD at 0_47 micron_47',\n",
       " 'AOD at 0_47 micron_48',\n",
       " 'AOD at 0_47 micron_49',\n",
       " 'AOD at 0_47 micron_50',\n",
       " 'AOD at 0_47 micron_51',\n",
       " 'AOD at 0_47 micron_52',\n",
       " 'AOD at 0_47 micron_53',\n",
       " 'AOD at 0_47 micron_54',\n",
       " 'AOD at 0_47 micron_55',\n",
       " 'AOD at 0_47 micron_56',\n",
       " 'AOD at 0_47 micron_57',\n",
       " 'AOD at 0_47 micron_58',\n",
       " 'AOD at 0_47 micron_59',\n",
       " 'AOD at 0_47 micron_60',\n",
       " 'AOD at 0_47 micron_61',\n",
       " 'AOD at 0_47 micron_62',\n",
       " 'AOD at 0_47 micron_63',\n",
       " 'AOD at 0_47 micron_64',\n",
       " 'AOD at 0_47 micron_65',\n",
       " 'AOD at 0_47 micron_66',\n",
       " 'AOD at 0_47 micron_67',\n",
       " 'AOD at 0_47 micron_68',\n",
       " 'AOD at 0_47 micron_69',\n",
       " 'AOD at 0_47 micron_70',\n",
       " 'AOD at 0_47 micron_71',\n",
       " 'AOD at 0_47 micron_72',\n",
       " 'AOD at 0_47 micron_73',\n",
       " 'AOD at 0_47 micron_74',\n",
       " 'AOD at 0_47 micron_75',\n",
       " 'AOD at 0_47 micron_76',\n",
       " 'AOD at 0_47 micron_77',\n",
       " 'AOD at 0_47 micron_78',\n",
       " 'AOD at 0_47 micron_79',\n",
       " 'AOD at 0_47 micron_80',\n",
       " 'AOD at 0_47 micron_81',\n",
       " 'AOD at 0_47 micron_82',\n",
       " 'AOD at 0_47 micron_83',\n",
       " 'AOD at 0_47 micron_84',\n",
       " 'AOD at 0_47 micron_85',\n",
       " 'AOD at 0_47 micron_86',\n",
       " 'AOD at 0_47 micron_87',\n",
       " 'AOD at 0_47 micron_88',\n",
       " 'AOD at 0_47 micron_89',\n",
       " 'AOD at 0_47 micron_90',\n",
       " 'AOD at 0_47 micron_91',\n",
       " 'AOD at 0_47 micron_92',\n",
       " 'AOD at 0_47 micron_93',\n",
       " 'AOD at 0_47 micron_94',\n",
       " 'AOD at 0_47 micron_95',\n",
       " 'AOD at 0_47 micron_96',\n",
       " 'AOD at 0_47 micron_97',\n",
       " 'AOD at 0_47 micron_98',\n",
       " 'AOD at 0_47 micron_99',\n",
       " 'AOD at 0_47 micron_100',\n",
       " 'AOD at 0_47 micron_101',\n",
       " 'AOD at 0_47 micron_102',\n",
       " 'AOD at 0_47 micron_103',\n",
       " 'AOD at 0_47 micron_104',\n",
       " 'AOD at 0_47 micron_105',\n",
       " 'AOD at 0_47 micron_106',\n",
       " 'AOD at 0_47 micron_107',\n",
       " 'AOD at 0_47 micron_108',\n",
       " 'AOD at 0_47 micron_109',\n",
       " 'AOD at 0_47 micron_110',\n",
       " 'AOD at 0_47 micron_111',\n",
       " 'AOD at 0_47 micron_112',\n",
       " 'AOD at 0_47 micron_113',\n",
       " 'AOD at 0_47 micron_114',\n",
       " 'AOD at 0_47 micron_115',\n",
       " 'AOD at 0_47 micron_116',\n",
       " 'AOD at 0_47 micron_117',\n",
       " 'AOD at 0_47 micron_118',\n",
       " 'AOD at 0_47 micron_119',\n",
       " 'AOD at 0_47 micron_120',\n",
       " 'AOD at 0_47 micron_121',\n",
       " 'AOD at 0_47 micron_122',\n",
       " 'AOD at 0_47 micron_123',\n",
       " 'AOD at 0_47 micron_124',\n",
       " 'AOD at 0_47 micron_125',\n",
       " 'AOD at 0_47 micron_126',\n",
       " 'AOD at 0_47 micron_127',\n",
       " 'AOD at 0_47 micron_128',\n",
       " 'AOD at 0_47 micron_129',\n",
       " 'AOD at 0_47 micron_130',\n",
       " 'AOD at 0_47 micron_131',\n",
       " 'AOD at 0_47 micron_132',\n",
       " 'AOD at 0_47 micron_133',\n",
       " 'AOD at 0_47 micron_134',\n",
       " 'AOD at 0_47 micron_135',\n",
       " 'AOD at 0_47 micron_136',\n",
       " 'AOD at 0_47 micron_137',\n",
       " 'AOD at 0_47 micron_138',\n",
       " 'AOD at 0_47 micron_139',\n",
       " 'AOD at 0_47 micron_140',\n",
       " 'AOD at 0_47 micron_141',\n",
       " 'AOD at 0_47 micron_142',\n",
       " 'AOD at 0_47 micron_143',\n",
       " 'AOD at 0_47 micron_144',\n",
       " 'AOD at 0_47 micron_145',\n",
       " 'AOD at 0_47 micron_146',\n",
       " 'AOD at 0_47 micron_147',\n",
       " 'AOD at 0_47 micron_148',\n",
       " 'AOD at 0_47 micron_149',\n",
       " 'AOD at 0_47 micron_150',\n",
       " 'AOD at 0_47 micron_151',\n",
       " 'AOD at 0_47 micron_152',\n",
       " 'AOD at 0_47 micron_153',\n",
       " 'AOD at 0_47 micron_154',\n",
       " 'AOD at 0_47 micron_155',\n",
       " 'AOD at 0_47 micron_156',\n",
       " 'AOD at 0_47 micron_157',\n",
       " 'AOD at 0_47 micron_158',\n",
       " 'AOD at 0_47 micron_159',\n",
       " 'AOD at 0_47 micron_160',\n",
       " 'AOD at 0_47 micron_161',\n",
       " 'AOD at 0_47 micron_162',\n",
       " 'AOD at 0_47 micron_163',\n",
       " 'AOD at 0_47 micron_164',\n",
       " 'AOD at 0_47 micron_165',\n",
       " 'AOD at 0_47 micron_166',\n",
       " 'AOD at 0_47 micron_167',\n",
       " 'AOD at 0_47 micron_168',\n",
       " 'AOD at 0_47 micron_169',\n",
       " 'AOD at 0_47 micron_170',\n",
       " 'AOD at 0_47 micron_171',\n",
       " 'AOD at 0_47 micron_172',\n",
       " 'AOD at 0_47 micron_173',\n",
       " 'AOD at 0_47 micron_174',\n",
       " 'AOD at 0_47 micron_175',\n",
       " 'AOD at 0_47 micron_176',\n",
       " 'AOD at 0_47 micron_177',\n",
       " 'AOD at 0_47 micron_178',\n",
       " 'AOD at 0_47 micron_179',\n",
       " 'AOD at 0_47 micron_180',\n",
       " 'AOD at 0_47 micron_181',\n",
       " 'AOD at 0_47 micron_182',\n",
       " 'AOD at 0_47 micron_183',\n",
       " 'AOD at 0_47 micron_184',\n",
       " 'AOD at 0_47 micron_185',\n",
       " 'AOD at 0_47 micron_186',\n",
       " 'AOD at 0_47 micron_187',\n",
       " 'AOD at 0_47 micron_188',\n",
       " 'AOD at 0_47 micron_189',\n",
       " 'AOD at 0_47 micron_190',\n",
       " 'AOD at 0_47 micron_191',\n",
       " 'AOD at 0_47 micron_192',\n",
       " 'AOD at 0_47 micron_193',\n",
       " 'AOD at 0_47 micron_194',\n",
       " 'AOD at 0_47 micron_195',\n",
       " 'AOD at 0_47 micron_196',\n",
       " 'AOD at 0_47 micron_197',\n",
       " 'AOD at 0_47 micron_198',\n",
       " 'AOD at 0_47 micron_199',\n",
       " 'AOD at 0_47 micron_200',\n",
       " 'AOD at 0_47 micron_201',\n",
       " 'AOD at 0_47 micron_202',\n",
       " 'AOD at 0_47 micron_203',\n",
       " 'AOD at 0_47 micron_204',\n",
       " 'AOD at 0_47 micron_205',\n",
       " 'AOD at 0_47 micron_206',\n",
       " 'AOD at 0_47 micron_207',\n",
       " 'AOD at 0_47 micron_208',\n",
       " 'AOD at 0_47 micron_209',\n",
       " 'AOD at 0_47 micron_210',\n",
       " 'AOD at 0_47 micron_211',\n",
       " 'AOD at 0_47 micron_212',\n",
       " 'AOD at 0_47 micron_213',\n",
       " 'AOD at 0_47 micron_214',\n",
       " 'AOD at 0_47 micron_215',\n",
       " 'AOD at 0_47 micron_216',\n",
       " 'AOD at 0_47 micron_217',\n",
       " 'AOD at 0_47 micron_218',\n",
       " 'AOD at 0_47 micron_219',\n",
       " 'AOD at 0_47 micron_220',\n",
       " 'AOD at 0_47 micron_221',\n",
       " 'AOD at 0_47 micron_222',\n",
       " 'AOD at 0_47 micron_223',\n",
       " 'AOD at 0_47 micron_224',\n",
       " 'AOD at 0_47 micron_225',\n",
       " 'AOD at 0_47 micron_226',\n",
       " 'AOD at 0_47 micron_227',\n",
       " 'AOD at 0_47 micron_228',\n",
       " 'AOD at 0_47 micron_229',\n",
       " 'AOD at 0_47 micron_230',\n",
       " 'AOD at 0_47 micron_231',\n",
       " 'AOD at 0_47 micron_232',\n",
       " 'AOD at 0_47 micron_233',\n",
       " 'AOD at 0_47 micron_234',\n",
       " 'AOD at 0_47 micron_235',\n",
       " 'AOD at 0_47 micron_236',\n",
       " 'AOD at 0_47 micron_237',\n",
       " 'AOD at 0_47 micron_238',\n",
       " 'AOD at 0_47 micron_239',\n",
       " 'AOD at 0_47 micron_240',\n",
       " 'AOD at 0_47 micron_241',\n",
       " 'AOD at 0_47 micron_242',\n",
       " 'AOD at 0_47 micron_243',\n",
       " 'AOD at 0_47 micron_244',\n",
       " 'AOD at 0_47 micron_245',\n",
       " 'AOD at 0_47 micron_246',\n",
       " 'AOD at 0_47 micron_247',\n",
       " 'AOD at 0_47 micron_248',\n",
       " 'AOD at 0_47 micron_249',\n",
       " 'AOD at 0_47 micron_250',\n",
       " 'AOD at 0_47 micron_251',\n",
       " 'AOD at 0_47 micron_252',\n",
       " 'AOD at 0_47 micron_253',\n",
       " 'AOD at 0_47 micron_254',\n",
       " 'AOD at 0_47 micron_255',\n",
       " 'AOD at 0_55 micron_0',\n",
       " 'AOD at 0_55 micron_1',\n",
       " 'AOD at 0_55 micron_2',\n",
       " 'AOD at 0_55 micron_3',\n",
       " 'AOD at 0_55 micron_4',\n",
       " 'AOD at 0_55 micron_5',\n",
       " 'AOD at 0_55 micron_6',\n",
       " 'AOD at 0_55 micron_7',\n",
       " 'AOD at 0_55 micron_8',\n",
       " 'AOD at 0_55 micron_9',\n",
       " 'AOD at 0_55 micron_10',\n",
       " 'AOD at 0_55 micron_11',\n",
       " 'AOD at 0_55 micron_12',\n",
       " 'AOD at 0_55 micron_13',\n",
       " 'AOD at 0_55 micron_14',\n",
       " 'AOD at 0_55 micron_15',\n",
       " 'AOD at 0_55 micron_16',\n",
       " 'AOD at 0_55 micron_17',\n",
       " 'AOD at 0_55 micron_18',\n",
       " 'AOD at 0_55 micron_19',\n",
       " 'AOD at 0_55 micron_20',\n",
       " 'AOD at 0_55 micron_21',\n",
       " 'AOD at 0_55 micron_22',\n",
       " 'AOD at 0_55 micron_23',\n",
       " 'AOD at 0_55 micron_24',\n",
       " 'AOD at 0_55 micron_25',\n",
       " 'AOD at 0_55 micron_26',\n",
       " 'AOD at 0_55 micron_27',\n",
       " 'AOD at 0_55 micron_28',\n",
       " 'AOD at 0_55 micron_29',\n",
       " 'AOD at 0_55 micron_30',\n",
       " 'AOD at 0_55 micron_31',\n",
       " 'AOD at 0_55 micron_32',\n",
       " 'AOD at 0_55 micron_33',\n",
       " 'AOD at 0_55 micron_34',\n",
       " 'AOD at 0_55 micron_35',\n",
       " 'AOD at 0_55 micron_36',\n",
       " 'AOD at 0_55 micron_37',\n",
       " 'AOD at 0_55 micron_38',\n",
       " 'AOD at 0_55 micron_39',\n",
       " 'AOD at 0_55 micron_40',\n",
       " 'AOD at 0_55 micron_41',\n",
       " 'AOD at 0_55 micron_42',\n",
       " 'AOD at 0_55 micron_43',\n",
       " 'AOD at 0_55 micron_44',\n",
       " 'AOD at 0_55 micron_45',\n",
       " 'AOD at 0_55 micron_46',\n",
       " 'AOD at 0_55 micron_47',\n",
       " 'AOD at 0_55 micron_48',\n",
       " 'AOD at 0_55 micron_49',\n",
       " 'AOD at 0_55 micron_50',\n",
       " 'AOD at 0_55 micron_51',\n",
       " 'AOD at 0_55 micron_52',\n",
       " 'AOD at 0_55 micron_53',\n",
       " 'AOD at 0_55 micron_54',\n",
       " 'AOD at 0_55 micron_55',\n",
       " 'AOD at 0_55 micron_56',\n",
       " 'AOD at 0_55 micron_57',\n",
       " 'AOD at 0_55 micron_58',\n",
       " 'AOD at 0_55 micron_59',\n",
       " 'AOD at 0_55 micron_60',\n",
       " 'AOD at 0_55 micron_61',\n",
       " 'AOD at 0_55 micron_62',\n",
       " 'AOD at 0_55 micron_63',\n",
       " 'AOD at 0_55 micron_64',\n",
       " 'AOD at 0_55 micron_65',\n",
       " 'AOD at 0_55 micron_66',\n",
       " 'AOD at 0_55 micron_67',\n",
       " 'AOD at 0_55 micron_68',\n",
       " 'AOD at 0_55 micron_69',\n",
       " 'AOD at 0_55 micron_70',\n",
       " 'AOD at 0_55 micron_71',\n",
       " 'AOD at 0_55 micron_72',\n",
       " 'AOD at 0_55 micron_73',\n",
       " 'AOD at 0_55 micron_74',\n",
       " 'AOD at 0_55 micron_75',\n",
       " 'AOD at 0_55 micron_76',\n",
       " 'AOD at 0_55 micron_77',\n",
       " 'AOD at 0_55 micron_78',\n",
       " 'AOD at 0_55 micron_79',\n",
       " 'AOD at 0_55 micron_80',\n",
       " 'AOD at 0_55 micron_81',\n",
       " 'AOD at 0_55 micron_82',\n",
       " 'AOD at 0_55 micron_83',\n",
       " 'AOD at 0_55 micron_84',\n",
       " 'AOD at 0_55 micron_85',\n",
       " 'AOD at 0_55 micron_86',\n",
       " 'AOD at 0_55 micron_87',\n",
       " 'AOD at 0_55 micron_88',\n",
       " 'AOD at 0_55 micron_89',\n",
       " 'AOD at 0_55 micron_90',\n",
       " 'AOD at 0_55 micron_91',\n",
       " 'AOD at 0_55 micron_92',\n",
       " 'AOD at 0_55 micron_93',\n",
       " 'AOD at 0_55 micron_94',\n",
       " 'AOD at 0_55 micron_95',\n",
       " 'AOD at 0_55 micron_96',\n",
       " 'AOD at 0_55 micron_97',\n",
       " 'AOD at 0_55 micron_98',\n",
       " 'AOD at 0_55 micron_99',\n",
       " 'AOD at 0_55 micron_100',\n",
       " 'AOD at 0_55 micron_101',\n",
       " 'AOD at 0_55 micron_102',\n",
       " 'AOD at 0_55 micron_103',\n",
       " 'AOD at 0_55 micron_104',\n",
       " 'AOD at 0_55 micron_105',\n",
       " 'AOD at 0_55 micron_106',\n",
       " 'AOD at 0_55 micron_107',\n",
       " 'AOD at 0_55 micron_108',\n",
       " 'AOD at 0_55 micron_109',\n",
       " 'AOD at 0_55 micron_110',\n",
       " 'AOD at 0_55 micron_111',\n",
       " 'AOD at 0_55 micron_112',\n",
       " 'AOD at 0_55 micron_113',\n",
       " 'AOD at 0_55 micron_114',\n",
       " 'AOD at 0_55 micron_115',\n",
       " 'AOD at 0_55 micron_116',\n",
       " 'AOD at 0_55 micron_117',\n",
       " 'AOD at 0_55 micron_118',\n",
       " 'AOD at 0_55 micron_119',\n",
       " 'AOD at 0_55 micron_120',\n",
       " 'AOD at 0_55 micron_121',\n",
       " 'AOD at 0_55 micron_122',\n",
       " 'AOD at 0_55 micron_123',\n",
       " 'AOD at 0_55 micron_124',\n",
       " 'AOD at 0_55 micron_125',\n",
       " 'AOD at 0_55 micron_126',\n",
       " 'AOD at 0_55 micron_127',\n",
       " 'AOD at 0_55 micron_128',\n",
       " 'AOD at 0_55 micron_129',\n",
       " 'AOD at 0_55 micron_130',\n",
       " 'AOD at 0_55 micron_131',\n",
       " 'AOD at 0_55 micron_132',\n",
       " 'AOD at 0_55 micron_133',\n",
       " 'AOD at 0_55 micron_134',\n",
       " 'AOD at 0_55 micron_135',\n",
       " 'AOD at 0_55 micron_136',\n",
       " 'AOD at 0_55 micron_137',\n",
       " 'AOD at 0_55 micron_138',\n",
       " 'AOD at 0_55 micron_139',\n",
       " 'AOD at 0_55 micron_140',\n",
       " 'AOD at 0_55 micron_141',\n",
       " 'AOD at 0_55 micron_142',\n",
       " 'AOD at 0_55 micron_143',\n",
       " 'AOD at 0_55 micron_144',\n",
       " 'AOD at 0_55 micron_145',\n",
       " 'AOD at 0_55 micron_146',\n",
       " 'AOD at 0_55 micron_147',\n",
       " 'AOD at 0_55 micron_148',\n",
       " 'AOD at 0_55 micron_149',\n",
       " 'AOD at 0_55 micron_150',\n",
       " 'AOD at 0_55 micron_151',\n",
       " 'AOD at 0_55 micron_152',\n",
       " 'AOD at 0_55 micron_153',\n",
       " 'AOD at 0_55 micron_154',\n",
       " 'AOD at 0_55 micron_155',\n",
       " 'AOD at 0_55 micron_156',\n",
       " 'AOD at 0_55 micron_157',\n",
       " 'AOD at 0_55 micron_158',\n",
       " 'AOD at 0_55 micron_159',\n",
       " 'AOD at 0_55 micron_160',\n",
       " 'AOD at 0_55 micron_161',\n",
       " 'AOD at 0_55 micron_162',\n",
       " 'AOD at 0_55 micron_163',\n",
       " 'AOD at 0_55 micron_164',\n",
       " 'AOD at 0_55 micron_165',\n",
       " 'AOD at 0_55 micron_166',\n",
       " 'AOD at 0_55 micron_167',\n",
       " 'AOD at 0_55 micron_168',\n",
       " 'AOD at 0_55 micron_169',\n",
       " 'AOD at 0_55 micron_170',\n",
       " 'AOD at 0_55 micron_171',\n",
       " 'AOD at 0_55 micron_172',\n",
       " 'AOD at 0_55 micron_173',\n",
       " 'AOD at 0_55 micron_174',\n",
       " 'AOD at 0_55 micron_175',\n",
       " 'AOD at 0_55 micron_176',\n",
       " 'AOD at 0_55 micron_177',\n",
       " 'AOD at 0_55 micron_178',\n",
       " 'AOD at 0_55 micron_179',\n",
       " 'AOD at 0_55 micron_180',\n",
       " 'AOD at 0_55 micron_181',\n",
       " 'AOD at 0_55 micron_182',\n",
       " 'AOD at 0_55 micron_183',\n",
       " 'AOD at 0_55 micron_184',\n",
       " 'AOD at 0_55 micron_185',\n",
       " 'AOD at 0_55 micron_186',\n",
       " 'AOD at 0_55 micron_187',\n",
       " 'AOD at 0_55 micron_188',\n",
       " 'AOD at 0_55 micron_189',\n",
       " 'AOD at 0_55 micron_190',\n",
       " 'AOD at 0_55 micron_191',\n",
       " 'AOD at 0_55 micron_192',\n",
       " 'AOD at 0_55 micron_193',\n",
       " 'AOD at 0_55 micron_194',\n",
       " 'AOD at 0_55 micron_195',\n",
       " 'AOD at 0_55 micron_196',\n",
       " 'AOD at 0_55 micron_197',\n",
       " 'AOD at 0_55 micron_198',\n",
       " 'AOD at 0_55 micron_199',\n",
       " 'AOD at 0_55 micron_200',\n",
       " 'AOD at 0_55 micron_201',\n",
       " 'AOD at 0_55 micron_202',\n",
       " 'AOD at 0_55 micron_203',\n",
       " 'AOD at 0_55 micron_204',\n",
       " 'AOD at 0_55 micron_205',\n",
       " 'AOD at 0_55 micron_206',\n",
       " 'AOD at 0_55 micron_207',\n",
       " 'AOD at 0_55 micron_208',\n",
       " 'AOD at 0_55 micron_209',\n",
       " 'AOD at 0_55 micron_210',\n",
       " 'AOD at 0_55 micron_211',\n",
       " 'AOD at 0_55 micron_212',\n",
       " 'AOD at 0_55 micron_213',\n",
       " 'AOD at 0_55 micron_214',\n",
       " 'AOD at 0_55 micron_215',\n",
       " 'AOD at 0_55 micron_216',\n",
       " 'AOD at 0_55 micron_217',\n",
       " 'AOD at 0_55 micron_218',\n",
       " 'AOD at 0_55 micron_219',\n",
       " 'AOD at 0_55 micron_220',\n",
       " 'AOD at 0_55 micron_221',\n",
       " 'AOD at 0_55 micron_222',\n",
       " 'AOD at 0_55 micron_223',\n",
       " 'AOD at 0_55 micron_224',\n",
       " 'AOD at 0_55 micron_225',\n",
       " 'AOD at 0_55 micron_226',\n",
       " 'AOD at 0_55 micron_227',\n",
       " 'AOD at 0_55 micron_228',\n",
       " 'AOD at 0_55 micron_229',\n",
       " 'AOD at 0_55 micron_230',\n",
       " 'AOD at 0_55 micron_231',\n",
       " 'AOD at 0_55 micron_232',\n",
       " 'AOD at 0_55 micron_233',\n",
       " 'AOD at 0_55 micron_234',\n",
       " 'AOD at 0_55 micron_235',\n",
       " 'AOD at 0_55 micron_236',\n",
       " 'AOD at 0_55 micron_237',\n",
       " 'AOD at 0_55 micron_238',\n",
       " 'AOD at 0_55 micron_239',\n",
       " 'AOD at 0_55 micron_240',\n",
       " 'AOD at 0_55 micron_241',\n",
       " 'AOD at 0_55 micron_242',\n",
       " 'AOD at 0_55 micron_243',\n",
       " 'AOD at 0_55 micron_244',\n",
       " 'AOD at 0_55 micron_245',\n",
       " 'AOD at 0_55 micron_246',\n",
       " 'AOD at 0_55 micron_247',\n",
       " 'AOD at 0_55 micron_248',\n",
       " 'AOD at 0_55 micron_249',\n",
       " 'AOD at 0_55 micron_250',\n",
       " 'AOD at 0_55 micron_251',\n",
       " 'AOD at 0_55 micron_252',\n",
       " 'AOD at 0_55 micron_253',\n",
       " 'AOD at 0_55 micron_254',\n",
       " 'AOD at 0_55 micron_255',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_0',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_1',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_2',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_3',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_4',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_5',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_6',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_7',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_8',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_9',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_10',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_11',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_12',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_13',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_14',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_15',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_16',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_17',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_18',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_19',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_20',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_21',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_22',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_23',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_24',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_25',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_26',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_27',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_28',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_29',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_30',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_31',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_32',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_33',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_34',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_35',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_36',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_37',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_38',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_39',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_40',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_41',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_42',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_43',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_44',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_45',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_46',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_47',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_48',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_49',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_50',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_51',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_52',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_53',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_54',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_55',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_56',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_57',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_58',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_59',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_60',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_61',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_62',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_63',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_64',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_65',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_66',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_67',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_68',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_69',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_70',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_71',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_72',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_73',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_74',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_75',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_76',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_77',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_78',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_79',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_80',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_81',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_82',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_83',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_84',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_85',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_86',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_87',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_88',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_89',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_90',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_91',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_92',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_93',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_94',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_95',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_96',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_97',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_98',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_99',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_100',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_101',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_102',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_103',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_104',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_105',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_106',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_107',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_108',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_109',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_110',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_111',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_112',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_113',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_114',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_115',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_116',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_117',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_118',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_119',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_120',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_121',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_122',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_123',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_124',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_125',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_126',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_127',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_128',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_129',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_130',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_131',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_132',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_133',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_134',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_135',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_136',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_137',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_138',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_139',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_140',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_141',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_142',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_143',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_144',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_145',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_146',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_147',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_148',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_149',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_150',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_151',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_152',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_153',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_154',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_155',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_156',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_157',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_158',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_159',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_160',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_161',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_162',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_163',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_164',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_165',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_166',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_167',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_168',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_169',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_170',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_171',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_172',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_173',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_174',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_175',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_176',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_177',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_178',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_179',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_180',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_181',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_182',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_183',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_184',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_185',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_186',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_187',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_188',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_189',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_190',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_191',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_192',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_193',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_194',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_195',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_196',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_197',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_198',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_199',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_200',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_201',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_202',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_203',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_204',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_205',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_206',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_207',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_208',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_209',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_210',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_211',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_212',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_213',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_214',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_215',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_216',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_217',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_218',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_219',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_220',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_221',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_222',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_223',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_224',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_225',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_226',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_227',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_228',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_229',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_230',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_231',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_232',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_233',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_234',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_235',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_236',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_237',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_238',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_239',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_240',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_241',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_242',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_243',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_244',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_245',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_246',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_247',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_248',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_249',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_250',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_251',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_252',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_253',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_254',\n",
       " 'AOD uncertainty at 0_47 micron, range 0-4_255',\n",
       " 'Fine mode fraction for Ocean_0',\n",
       " 'Fine mode fraction for Ocean_1',\n",
       " 'Fine mode fraction for Ocean_2',\n",
       " 'Fine mode fraction for Ocean_3',\n",
       " 'Fine mode fraction for Ocean_4',\n",
       " 'Fine mode fraction for Ocean_5',\n",
       " 'Fine mode fraction for Ocean_6',\n",
       " 'Fine mode fraction for Ocean_7',\n",
       " 'Fine mode fraction for Ocean_8',\n",
       " 'Fine mode fraction for Ocean_9',\n",
       " 'Fine mode fraction for Ocean_10',\n",
       " 'Fine mode fraction for Ocean_11',\n",
       " 'Fine mode fraction for Ocean_12',\n",
       " 'Fine mode fraction for Ocean_13',\n",
       " 'Fine mode fraction for Ocean_14',\n",
       " 'Fine mode fraction for Ocean_15',\n",
       " 'Fine mode fraction for Ocean_16',\n",
       " 'Fine mode fraction for Ocean_17',\n",
       " 'Fine mode fraction for Ocean_18',\n",
       " 'Fine mode fraction for Ocean_19',\n",
       " 'Fine mode fraction for Ocean_20',\n",
       " 'Fine mode fraction for Ocean_21',\n",
       " 'Fine mode fraction for Ocean_22',\n",
       " 'Fine mode fraction for Ocean_23',\n",
       " 'Fine mode fraction for Ocean_24',\n",
       " 'Fine mode fraction for Ocean_25',\n",
       " 'Fine mode fraction for Ocean_26',\n",
       " 'Fine mode fraction for Ocean_27',\n",
       " 'Fine mode fraction for Ocean_28',\n",
       " 'Fine mode fraction for Ocean_29',\n",
       " 'Fine mode fraction for Ocean_30',\n",
       " 'Fine mode fraction for Ocean_31',\n",
       " 'Fine mode fraction for Ocean_32',\n",
       " 'Fine mode fraction for Ocean_33',\n",
       " 'Fine mode fraction for Ocean_34',\n",
       " 'Fine mode fraction for Ocean_35',\n",
       " 'Fine mode fraction for Ocean_36',\n",
       " 'Fine mode fraction for Ocean_37',\n",
       " 'Fine mode fraction for Ocean_38',\n",
       " 'Fine mode fraction for Ocean_39',\n",
       " 'Fine mode fraction for Ocean_40',\n",
       " 'Fine mode fraction for Ocean_41',\n",
       " 'Fine mode fraction for Ocean_42',\n",
       " 'Fine mode fraction for Ocean_43',\n",
       " 'Fine mode fraction for Ocean_44',\n",
       " 'Fine mode fraction for Ocean_45',\n",
       " 'Fine mode fraction for Ocean_46',\n",
       " 'Fine mode fraction for Ocean_47',\n",
       " 'Fine mode fraction for Ocean_48',\n",
       " 'Fine mode fraction for Ocean_49',\n",
       " 'Fine mode fraction for Ocean_50',\n",
       " 'Fine mode fraction for Ocean_51',\n",
       " 'Fine mode fraction for Ocean_52',\n",
       " 'Fine mode fraction for Ocean_53',\n",
       " 'Fine mode fraction for Ocean_54',\n",
       " 'Fine mode fraction for Ocean_55',\n",
       " 'Fine mode fraction for Ocean_56',\n",
       " 'Fine mode fraction for Ocean_57',\n",
       " 'Fine mode fraction for Ocean_58',\n",
       " 'Fine mode fraction for Ocean_59',\n",
       " 'Fine mode fraction for Ocean_60',\n",
       " 'Fine mode fraction for Ocean_61',\n",
       " 'Fine mode fraction for Ocean_62',\n",
       " 'Fine mode fraction for Ocean_63',\n",
       " 'Fine mode fraction for Ocean_64',\n",
       " 'Fine mode fraction for Ocean_65',\n",
       " 'Fine mode fraction for Ocean_66',\n",
       " 'Fine mode fraction for Ocean_67',\n",
       " 'Fine mode fraction for Ocean_68',\n",
       " 'Fine mode fraction for Ocean_69',\n",
       " 'Fine mode fraction for Ocean_70',\n",
       " 'Fine mode fraction for Ocean_71',\n",
       " 'Fine mode fraction for Ocean_72',\n",
       " 'Fine mode fraction for Ocean_73',\n",
       " 'Fine mode fraction for Ocean_74',\n",
       " 'Fine mode fraction for Ocean_75',\n",
       " 'Fine mode fraction for Ocean_76',\n",
       " 'Fine mode fraction for Ocean_77',\n",
       " 'Fine mode fraction for Ocean_78',\n",
       " 'Fine mode fraction for Ocean_79',\n",
       " 'Fine mode fraction for Ocean_80',\n",
       " 'Fine mode fraction for Ocean_81',\n",
       " 'Fine mode fraction for Ocean_82',\n",
       " 'Fine mode fraction for Ocean_83',\n",
       " 'Fine mode fraction for Ocean_84',\n",
       " 'Fine mode fraction for Ocean_85',\n",
       " 'Fine mode fraction for Ocean_86',\n",
       " 'Fine mode fraction for Ocean_87',\n",
       " 'Fine mode fraction for Ocean_88',\n",
       " 'Fine mode fraction for Ocean_89',\n",
       " 'Fine mode fraction for Ocean_90',\n",
       " 'Fine mode fraction for Ocean_91',\n",
       " 'Fine mode fraction for Ocean_92',\n",
       " 'Fine mode fraction for Ocean_93',\n",
       " 'Fine mode fraction for Ocean_94',\n",
       " 'Fine mode fraction for Ocean_95',\n",
       " 'Fine mode fraction for Ocean_96',\n",
       " 'Fine mode fraction for Ocean_97',\n",
       " 'Fine mode fraction for Ocean_98',\n",
       " 'Fine mode fraction for Ocean_99',\n",
       " 'Fine mode fraction for Ocean_100',\n",
       " 'Fine mode fraction for Ocean_101',\n",
       " 'Fine mode fraction for Ocean_102',\n",
       " 'Fine mode fraction for Ocean_103',\n",
       " 'Fine mode fraction for Ocean_104',\n",
       " 'Fine mode fraction for Ocean_105',\n",
       " 'Fine mode fraction for Ocean_106',\n",
       " 'Fine mode fraction for Ocean_107',\n",
       " 'Fine mode fraction for Ocean_108',\n",
       " 'Fine mode fraction for Ocean_109',\n",
       " 'Fine mode fraction for Ocean_110',\n",
       " 'Fine mode fraction for Ocean_111',\n",
       " 'Fine mode fraction for Ocean_112',\n",
       " 'Fine mode fraction for Ocean_113',\n",
       " 'Fine mode fraction for Ocean_114',\n",
       " 'Fine mode fraction for Ocean_115',\n",
       " 'Fine mode fraction for Ocean_116',\n",
       " 'Fine mode fraction for Ocean_117',\n",
       " 'Fine mode fraction for Ocean_118',\n",
       " 'Fine mode fraction for Ocean_119',\n",
       " 'Fine mode fraction for Ocean_120',\n",
       " 'Fine mode fraction for Ocean_121',\n",
       " 'Fine mode fraction for Ocean_122',\n",
       " 'Fine mode fraction for Ocean_123',\n",
       " 'Fine mode fraction for Ocean_124',\n",
       " 'Fine mode fraction for Ocean_125',\n",
       " 'Fine mode fraction for Ocean_126',\n",
       " 'Fine mode fraction for Ocean_127',\n",
       " 'Fine mode fraction for Ocean_128',\n",
       " 'Fine mode fraction for Ocean_129',\n",
       " 'Fine mode fraction for Ocean_130',\n",
       " 'Fine mode fraction for Ocean_131',\n",
       " 'Fine mode fraction for Ocean_132',\n",
       " 'Fine mode fraction for Ocean_133',\n",
       " 'Fine mode fraction for Ocean_134',\n",
       " 'Fine mode fraction for Ocean_135',\n",
       " 'Fine mode fraction for Ocean_136',\n",
       " 'Fine mode fraction for Ocean_137',\n",
       " 'Fine mode fraction for Ocean_138',\n",
       " 'Fine mode fraction for Ocean_139',\n",
       " 'Fine mode fraction for Ocean_140',\n",
       " 'Fine mode fraction for Ocean_141',\n",
       " 'Fine mode fraction for Ocean_142',\n",
       " 'Fine mode fraction for Ocean_143',\n",
       " 'Fine mode fraction for Ocean_144',\n",
       " 'Fine mode fraction for Ocean_145',\n",
       " 'Fine mode fraction for Ocean_146',\n",
       " 'Fine mode fraction for Ocean_147',\n",
       " 'Fine mode fraction for Ocean_148',\n",
       " 'Fine mode fraction for Ocean_149',\n",
       " 'Fine mode fraction for Ocean_150',\n",
       " 'Fine mode fraction for Ocean_151',\n",
       " 'Fine mode fraction for Ocean_152',\n",
       " 'Fine mode fraction for Ocean_153',\n",
       " 'Fine mode fraction for Ocean_154',\n",
       " 'Fine mode fraction for Ocean_155',\n",
       " 'Fine mode fraction for Ocean_156',\n",
       " 'Fine mode fraction for Ocean_157',\n",
       " 'Fine mode fraction for Ocean_158',\n",
       " 'Fine mode fraction for Ocean_159',\n",
       " 'Fine mode fraction for Ocean_160',\n",
       " 'Fine mode fraction for Ocean_161',\n",
       " 'Fine mode fraction for Ocean_162',\n",
       " 'Fine mode fraction for Ocean_163',\n",
       " 'Fine mode fraction for Ocean_164',\n",
       " 'Fine mode fraction for Ocean_165',\n",
       " 'Fine mode fraction for Ocean_166',\n",
       " 'Fine mode fraction for Ocean_167',\n",
       " 'Fine mode fraction for Ocean_168',\n",
       " 'Fine mode fraction for Ocean_169',\n",
       " 'Fine mode fraction for Ocean_170',\n",
       " 'Fine mode fraction for Ocean_171',\n",
       " 'Fine mode fraction for Ocean_172',\n",
       " 'Fine mode fraction for Ocean_173',\n",
       " 'Fine mode fraction for Ocean_174',\n",
       " 'Fine mode fraction for Ocean_175',\n",
       " 'Fine mode fraction for Ocean_176',\n",
       " 'Fine mode fraction for Ocean_177',\n",
       " 'Fine mode fraction for Ocean_178',\n",
       " 'Fine mode fraction for Ocean_179',\n",
       " 'Fine mode fraction for Ocean_180',\n",
       " 'Fine mode fraction for Ocean_181',\n",
       " 'Fine mode fraction for Ocean_182',\n",
       " 'Fine mode fraction for Ocean_183',\n",
       " 'Fine mode fraction for Ocean_184',\n",
       " 'Fine mode fraction for Ocean_185',\n",
       " 'Fine mode fraction for Ocean_186',\n",
       " 'Fine mode fraction for Ocean_187',\n",
       " 'Fine mode fraction for Ocean_188',\n",
       " 'Fine mode fraction for Ocean_189',\n",
       " 'Fine mode fraction for Ocean_190',\n",
       " 'Fine mode fraction for Ocean_191',\n",
       " 'Fine mode fraction for Ocean_192',\n",
       " 'Fine mode fraction for Ocean_193',\n",
       " 'Fine mode fraction for Ocean_194',\n",
       " 'Fine mode fraction for Ocean_195',\n",
       " 'Fine mode fraction for Ocean_196',\n",
       " 'Fine mode fraction for Ocean_197',\n",
       " 'Fine mode fraction for Ocean_198',\n",
       " 'Fine mode fraction for Ocean_199',\n",
       " 'Fine mode fraction for Ocean_200',\n",
       " 'Fine mode fraction for Ocean_201',\n",
       " 'Fine mode fraction for Ocean_202',\n",
       " 'Fine mode fraction for Ocean_203',\n",
       " 'Fine mode fraction for Ocean_204',\n",
       " 'Fine mode fraction for Ocean_205',\n",
       " 'Fine mode fraction for Ocean_206',\n",
       " 'Fine mode fraction for Ocean_207',\n",
       " 'Fine mode fraction for Ocean_208',\n",
       " 'Fine mode fraction for Ocean_209',\n",
       " 'Fine mode fraction for Ocean_210',\n",
       " 'Fine mode fraction for Ocean_211',\n",
       " 'Fine mode fraction for Ocean_212',\n",
       " 'Fine mode fraction for Ocean_213',\n",
       " 'Fine mode fraction for Ocean_214',\n",
       " 'Fine mode fraction for Ocean_215',\n",
       " 'Fine mode fraction for Ocean_216',\n",
       " 'Fine mode fraction for Ocean_217',\n",
       " 'Fine mode fraction for Ocean_218',\n",
       " 'Fine mode fraction for Ocean_219',\n",
       " 'Fine mode fraction for Ocean_220',\n",
       " 'Fine mode fraction for Ocean_221',\n",
       " 'Fine mode fraction for Ocean_222',\n",
       " 'Fine mode fraction for Ocean_223',\n",
       " 'Fine mode fraction for Ocean_224',\n",
       " 'Fine mode fraction for Ocean_225',\n",
       " 'Fine mode fraction for Ocean_226',\n",
       " 'Fine mode fraction for Ocean_227',\n",
       " 'Fine mode fraction for Ocean_228',\n",
       " 'Fine mode fraction for Ocean_229',\n",
       " 'Fine mode fraction for Ocean_230',\n",
       " 'Fine mode fraction for Ocean_231',\n",
       " ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_varying_known_reals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cfb917d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = list(data.columns)[:4]+ time_varying_known_reals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55af02b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "012217db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_dt</th>\n",
       "      <th>location</th>\n",
       "      <th>AOD at 0_47 micron_0</th>\n",
       "      <th>AOD at 0_47 micron_1</th>\n",
       "      <th>AOD at 0_47 micron_2</th>\n",
       "      <th>AOD at 0_47 micron_3</th>\n",
       "      <th>AOD at 0_47 micron_4</th>\n",
       "      <th>AOD at 0_47 micron_5</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3S31A</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>2018-02-01 08:00:00+00:00</td>\n",
       "      <td>Los Angeles (SoCAB)</td>\n",
       "      <td>-0.563344</td>\n",
       "      <td>0.109907</td>\n",
       "      <td>-0.103034</td>\n",
       "      <td>0.234161</td>\n",
       "      <td>-0.041027</td>\n",
       "      <td>0.229606</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21430</th>\n",
       "      <td>P8JA5</td>\n",
       "      <td>146.370370</td>\n",
       "      <td>2018-02-01 18:30:00+00:00</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>-0.551273</td>\n",
       "      <td>0.114632</td>\n",
       "      <td>-0.116517</td>\n",
       "      <td>0.256812</td>\n",
       "      <td>-0.049742</td>\n",
       "      <td>0.242454</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21429</th>\n",
       "      <td>KZ9W9</td>\n",
       "      <td>101.304348</td>\n",
       "      <td>2018-02-01 18:30:00+00:00</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>-0.551273</td>\n",
       "      <td>0.114632</td>\n",
       "      <td>-0.116517</td>\n",
       "      <td>0.256812</td>\n",
       "      <td>-0.049742</td>\n",
       "      <td>0.242454</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21428</th>\n",
       "      <td>HM74A</td>\n",
       "      <td>154.875000</td>\n",
       "      <td>2018-02-01 18:30:00+00:00</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>-0.551273</td>\n",
       "      <td>0.114632</td>\n",
       "      <td>-0.116517</td>\n",
       "      <td>0.256812</td>\n",
       "      <td>-0.049742</td>\n",
       "      <td>0.242454</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21427</th>\n",
       "      <td>HANW9</td>\n",
       "      <td>148.687500</td>\n",
       "      <td>2018-02-01 18:30:00+00:00</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>-0.551273</td>\n",
       "      <td>0.114632</td>\n",
       "      <td>-0.116517</td>\n",
       "      <td>0.256812</td>\n",
       "      <td>-0.049742</td>\n",
       "      <td>0.242454</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21410</th>\n",
       "      <td>VR4WG</td>\n",
       "      <td>16.870968</td>\n",
       "      <td>2020-12-31 16:00:00+00:00</td>\n",
       "      <td>Taipei</td>\n",
       "      <td>-0.550836</td>\n",
       "      <td>0.114607</td>\n",
       "      <td>-0.116815</td>\n",
       "      <td>0.256702</td>\n",
       "      <td>-0.049746</td>\n",
       "      <td>0.242348</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21411</th>\n",
       "      <td>XJF9O</td>\n",
       "      <td>12.564516</td>\n",
       "      <td>2020-12-31 16:00:00+00:00</td>\n",
       "      <td>Taipei</td>\n",
       "      <td>-0.550836</td>\n",
       "      <td>0.114607</td>\n",
       "      <td>-0.116815</td>\n",
       "      <td>0.256702</td>\n",
       "      <td>-0.049746</td>\n",
       "      <td>0.242348</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21412</th>\n",
       "      <td>XNLVD</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>2020-12-31 16:00:00+00:00</td>\n",
       "      <td>Taipei</td>\n",
       "      <td>-0.550836</td>\n",
       "      <td>0.114607</td>\n",
       "      <td>-0.116815</td>\n",
       "      <td>0.256702</td>\n",
       "      <td>-0.049746</td>\n",
       "      <td>0.242348</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37204</th>\n",
       "      <td>ZF3ZW</td>\n",
       "      <td>410.500000</td>\n",
       "      <td>2020-12-31 18:30:00+00:00</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>-0.550824</td>\n",
       "      <td>0.114607</td>\n",
       "      <td>-0.116819</td>\n",
       "      <td>0.256715</td>\n",
       "      <td>-0.049741</td>\n",
       "      <td>0.242339</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37195</th>\n",
       "      <td>HANW9</td>\n",
       "      <td>399.463415</td>\n",
       "      <td>2020-12-31 18:30:00+00:00</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>-0.550824</td>\n",
       "      <td>0.114607</td>\n",
       "      <td>-0.116819</td>\n",
       "      <td>0.256715</td>\n",
       "      <td>-0.049741</td>\n",
       "      <td>0.242339</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39450 rows Ã— 2065 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      grid_id       value               datetime_dt             location  \\\n",
       "0       3S31A   11.400000 2018-02-01 08:00:00+00:00  Los Angeles (SoCAB)   \n",
       "21430   P8JA5  146.370370 2018-02-01 18:30:00+00:00                Delhi   \n",
       "21429   KZ9W9  101.304348 2018-02-01 18:30:00+00:00                Delhi   \n",
       "21428   HM74A  154.875000 2018-02-01 18:30:00+00:00                Delhi   \n",
       "21427   HANW9  148.687500 2018-02-01 18:30:00+00:00                Delhi   \n",
       "...       ...         ...                       ...                  ...   \n",
       "21410   VR4WG   16.870968 2020-12-31 16:00:00+00:00               Taipei   \n",
       "21411   XJF9O   12.564516 2020-12-31 16:00:00+00:00               Taipei   \n",
       "21412   XNLVD   12.500000 2020-12-31 16:00:00+00:00               Taipei   \n",
       "37204   ZF3ZW  410.500000 2020-12-31 18:30:00+00:00                Delhi   \n",
       "37195   HANW9  399.463415 2020-12-31 18:30:00+00:00                Delhi   \n",
       "\n",
       "       AOD at 0_47 micron_0  AOD at 0_47 micron_1  AOD at 0_47 micron_2  \\\n",
       "0                 -0.563344              0.109907             -0.103034   \n",
       "21430             -0.551273              0.114632             -0.116517   \n",
       "21429             -0.551273              0.114632             -0.116517   \n",
       "21428             -0.551273              0.114632             -0.116517   \n",
       "21427             -0.551273              0.114632             -0.116517   \n",
       "...                     ...                   ...                   ...   \n",
       "21410             -0.550836              0.114607             -0.116815   \n",
       "21411             -0.550836              0.114607             -0.116815   \n",
       "21412             -0.550836              0.114607             -0.116815   \n",
       "37204             -0.550824              0.114607             -0.116819   \n",
       "37195             -0.550824              0.114607             -0.116819   \n",
       "\n",
       "       AOD at 0_47 micron_3  AOD at 0_47 micron_4  AOD at 0_47 micron_5  ...  \\\n",
       "0                  0.234161             -0.041027              0.229606  ...   \n",
       "21430              0.256812             -0.049742              0.242454  ...   \n",
       "21429              0.256812             -0.049742              0.242454  ...   \n",
       "21428              0.256812             -0.049742              0.242454  ...   \n",
       "21427              0.256812             -0.049742              0.242454  ...   \n",
       "...                     ...                   ...                   ...  ...   \n",
       "21410              0.256702             -0.049746              0.242348  ...   \n",
       "21411              0.256702             -0.049746              0.242348  ...   \n",
       "21412              0.256702             -0.049746              0.242348  ...   \n",
       "37204              0.256715             -0.049741              0.242339  ...   \n",
       "37195              0.256715             -0.049741              0.242339  ...   \n",
       "\n",
       "       12  2  3  4  5  6  7  8  9  time_idx  \n",
       "0       0  1  0  0  0  0  0  0  0         0  \n",
       "21430   0  1  0  0  0  0  0  0  0         0  \n",
       "21429   0  1  0  0  0  0  0  0  0         0  \n",
       "21428   0  1  0  0  0  0  0  0  0         0  \n",
       "21427   0  1  0  0  0  0  0  0  0         0  \n",
       "...    .. .. .. .. .. .. .. .. ..       ...  \n",
       "21410   1  0  0  0  0  0  0  0  0      1060  \n",
       "21411   1  0  0  0  0  0  0  0  0      1060  \n",
       "21412   1  0  0  0  0  0  0  0  0      1060  \n",
       "37204   1  0  0  0  0  0  0  0  0      1060  \n",
       "37195   1  0  0  0  0  0  0  0  0      1060  \n",
       "\n",
       "[39450 rows x 2065 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c021778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"value\",\n",
    "    group_ids=[\"location\",\"grid_id\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[\"location\",\"grid_id\"],\n",
    "    time_varying_known_reals=time_varying_known_reals,\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"value\"\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[ \"location\",\"grid_id\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7109c59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _ConnectionBase.__del__ at 0x7f00f81bb940>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 132, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/queues.py\", line 235, in _feed\n",
      "    close()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "    self._close()\n",
      "  File \"/opt/conda/lib/python3.8/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1238: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 1 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__location': 'Delhi', '__group_id__grid_id': 'PJNW1'}]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=16)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "790fc836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.26200866699219"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d0306ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fafa4632",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchmetrics import MeanSquaredError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e26c443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=10,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "902b11bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 68.4k\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tft = RecurrentNetwork.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=8,  # most important hyperparameter apart from learning rate\n",
    "    rnn_layers= 2,\n",
    "    dropout=0.3,  # between 0.1 and 0.3 are good values\n",
    "    output_size=1,  \n",
    "    loss=RMSE(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c64891a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c104d33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type           | Params\n",
      "----------------------------------------------------\n",
      "0 | loss             | RMSE           | 0     \n",
      "1 | logging_metrics  | ModuleList     | 0     \n",
      "2 | embeddings       | MultiEmbedding | 819   \n",
      "3 | rnn              | LSTM           | 67.6 K\n",
      "4 | output_projector | Linear         | 9     \n",
      "----------------------------------------------------\n",
      "68.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "68.4 K    Total params\n",
      "0.274     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b14bc2226684f8486fefee82b5cb626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4156c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "index 1 is out of bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4af4987",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ({'encoder_cat': tensor([[[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]]), 'encoder_cont': tensor([[[ 8.8889, -1.0000,  0.0000,  ..., -1.7260, -4.9444, -0.1616],\n",
      "         [ 8.8889, -1.0000,  0.0000,  ..., -1.7260, -4.8889,  0.5079],\n",
      "         [ 8.8889, -1.0000,  0.0000,  ..., -1.7260, -4.8333, -0.1974],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[11.7778, -1.0000,  0.0000,  ..., -1.7260, -6.3889, -0.1616],\n",
      "         [11.7778, -1.0000,  0.0000,  ..., -1.7260, -6.3333,  0.5079],\n",
      "         [11.7778, -1.0000,  0.0000,  ..., -1.7260, -6.2778, -0.1974],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[17.1111, -1.0000,  0.0000,  ..., -1.1869, -9.0556, -0.1895],\n",
      "         [17.1111, -1.0000,  0.0000,  ..., -1.1869, -9.0000,  0.3817],\n",
      "         [17.1111, -1.0000,  0.0000,  ..., -1.0072, -8.9444, -0.2572],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[10.8889, -1.0000,  0.0000,  ..., -0.1087, -5.9444,  1.9425],\n",
      "         [10.8889, -1.0000,  0.0000,  ..., -0.1087, -5.8889,  1.6645],\n",
      "         [10.8889, -1.0000,  0.0000,  ..., -0.1087, -5.8333,  2.1786],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[18.8889, -1.0000,  0.0000,  ..., -1.7260, -9.9444,  0.9861],\n",
      "         [18.8889, -1.0000,  0.0000,  ..., -1.7260, -9.8889, -0.9028],\n",
      "         [18.8889, -1.0000,  0.0000,  ..., -1.7260, -9.8333, -0.7473],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[13.7778, -1.0000,  0.0000,  ..., -1.7260, -7.3889, -0.1616],\n",
      "         [13.7778, -1.0000,  0.0000,  ..., -1.7260, -7.3333,  0.5079],\n",
      "         [13.7778, -1.0000,  0.0000,  ..., -1.7260, -7.2778, -0.1974],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]), 'encoder_target': tensor([[11.4000, 17.0000, 11.1000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [11.4000, 17.0000, 11.1000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [11.1667, 15.9444, 10.6000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [29.0000, 26.6750, 30.9750,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [21.0000,  5.2000,  6.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [11.4000, 17.0000, 11.1000,  ...,  0.0000,  0.0000,  0.0000]]), 'encoder_lengths': tensor([ 89, 115, 163, 121, 180, 179, 175, 178, 168, 176, 144, 151, 137, 184,\n",
      "        175, 125, 182, 116, 115, 142, 159, 127, 182, 143,  86, 103,  97, 105,\n",
      "        120, 165, 159,  94, 174, 149, 139, 174, 126, 149, 116, 122, 108, 176,\n",
      "        170, 119, 123, 166, 108, 182, 136, 185, 176, 177, 152,  98, 178, 177,\n",
      "        173, 132, 153, 132, 172, 107, 179, 133]), 'decoder_cat': tensor([[[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]],\n",
      "\n",
      "        [[0]]]), 'decoder_cont': tensor([[[ 8.8889e+00, -1.0000e+00,  0.0000e+00,  ..., -1.0872e-01,\n",
      "           0.0000e+00,  1.4767e-02]],\n",
      "\n",
      "        [[ 1.1778e+01, -1.0000e+00,  0.0000e+00,  ...,  4.3037e-01,\n",
      "           0.0000e+00, -3.5882e-01]],\n",
      "\n",
      "        [[ 1.7111e+01, -1.0000e+00,  0.0000e+00,  ...,  1.6882e+00,\n",
      "           0.0000e+00, -1.0416e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0889e+01, -1.0000e+00,  0.0000e+00,  ...,  1.6882e+00,\n",
      "           0.0000e+00, -1.0416e+00]],\n",
      "\n",
      "        [[ 1.8889e+01, -1.0000e+00,  0.0000e+00,  ...,  1.5085e+00,\n",
      "           0.0000e+00, -1.1155e+00]],\n",
      "\n",
      "        [[ 1.3778e+01, -1.0000e+00,  0.0000e+00,  ...,  6.1007e-01,\n",
      "           0.0000e+00,  5.5245e-01]]]), 'decoder_target': tensor([[12.8750],\n",
      "        [ 9.7500],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [13.0737],\n",
      "        [ 4.8722],\n",
      "        [11.2789],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 7.3368],\n",
      "        [ 8.0077],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 3.4200],\n",
      "        [15.7000],\n",
      "        [ 4.0389],\n",
      "        [14.1000],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 6.9000],\n",
      "        [13.4300],\n",
      "        [ 6.8111],\n",
      "        [28.5500],\n",
      "        [ 4.4615],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [10.5000],\n",
      "        [ 5.4818],\n",
      "        [ 6.3750],\n",
      "        [ 9.2818],\n",
      "        [ 4.0389],\n",
      "        [ 4.9385],\n",
      "        [12.0200],\n",
      "        [ 7.9167],\n",
      "        [ 5.7364],\n",
      "        [ 4.0389],\n",
      "        [ 9.4000],\n",
      "        [12.7125],\n",
      "        [ 5.9667],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [25.7750],\n",
      "        [ 3.4200],\n",
      "        [ 3.4200],\n",
      "        [ 8.5100],\n",
      "        [ 7.5200],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 7.3750],\n",
      "        [ 4.0389],\n",
      "        [ 3.4200],\n",
      "        [17.3727]]), 'decoder_lengths': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'decoder_time_idx': tensor([[ 89],\n",
      "        [115],\n",
      "        [166],\n",
      "        [128],\n",
      "        [182],\n",
      "        [181],\n",
      "        [177],\n",
      "        [178],\n",
      "        [168],\n",
      "        [176],\n",
      "        [149],\n",
      "        [155],\n",
      "        [143],\n",
      "        [184],\n",
      "        [177],\n",
      "        [132],\n",
      "        [184],\n",
      "        [124],\n",
      "        [123],\n",
      "        [147],\n",
      "        [163],\n",
      "        [134],\n",
      "        [182],\n",
      "        [143],\n",
      "        [ 96],\n",
      "        [103],\n",
      "        [106],\n",
      "        [114],\n",
      "        [120],\n",
      "        [165],\n",
      "        [159],\n",
      "        [ 94],\n",
      "        [176],\n",
      "        [154],\n",
      "        [144],\n",
      "        [176],\n",
      "        [126],\n",
      "        [149],\n",
      "        [116],\n",
      "        [122],\n",
      "        [117],\n",
      "        [178],\n",
      "        [170],\n",
      "        [119],\n",
      "        [123],\n",
      "        [169],\n",
      "        [108],\n",
      "        [182],\n",
      "        [136],\n",
      "        [187],\n",
      "        [178],\n",
      "        [179],\n",
      "        [156],\n",
      "        [ 98],\n",
      "        [178],\n",
      "        [177],\n",
      "        [173],\n",
      "        [132],\n",
      "        [157],\n",
      "        [138],\n",
      "        [172],\n",
      "        [116],\n",
      "        [179],\n",
      "        [133]]), 'groups': tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]]), 'target_scale': tensor([[13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649],\n",
      "        [13.7515,  8.3649]])}, (tensor([[12.8750],\n",
      "        [ 9.7500],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [13.0737],\n",
      "        [ 4.8722],\n",
      "        [11.2789],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 7.3368],\n",
      "        [ 8.0077],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 3.4200],\n",
      "        [15.7000],\n",
      "        [ 4.0389],\n",
      "        [14.1000],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 6.9000],\n",
      "        [13.4300],\n",
      "        [ 6.8111],\n",
      "        [28.5500],\n",
      "        [ 4.4615],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [10.5000],\n",
      "        [ 5.4818],\n",
      "        [ 6.3750],\n",
      "        [ 9.2818],\n",
      "        [ 4.0389],\n",
      "        [ 4.9385],\n",
      "        [12.0200],\n",
      "        [ 7.9167],\n",
      "        [ 5.7364],\n",
      "        [ 4.0389],\n",
      "        [ 9.4000],\n",
      "        [12.7125],\n",
      "        [ 5.9667],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [25.7750],\n",
      "        [ 3.4200],\n",
      "        [ 3.4200],\n",
      "        [ 8.5100],\n",
      "        [ 7.5200],\n",
      "        [ 4.0389],\n",
      "        [ 4.0389],\n",
      "        [ 7.3750],\n",
      "        [ 4.0389],\n",
      "        [ 3.4200],\n",
      "        [17.3727]]), None))\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(train_dataloader):\n",
    "    print(i,j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09b7c2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoder_cat', 'encoder_cont', 'encoder_target', 'encoder_lengths', 'decoder_cat', 'decoder_cont', 'decoder_target', 'decoder_lengths', 'decoder_time_idx', 'groups', 'target_scale'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "45f19434",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "trainer.predict(model = tft, dataloaders=val_dataloader,return_predictions=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d0db0001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_forecasting/data/timeseries.py:1657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  target_scale = torch.tensor([batch[0][\"target_scale\"] for batch in batches], dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ({'encoder_cat': tensor([[[ 0,  1],\n",
      "         [ 0,  1],\n",
      "         [ 0,  1],\n",
      "         ...,\n",
      "         [ 0,  0],\n",
      "         [ 0,  0],\n",
      "         [ 0,  0]],\n",
      "\n",
      "        [[ 0,  3],\n",
      "         [ 0,  3],\n",
      "         [ 0,  3],\n",
      "         ...,\n",
      "         [ 0,  0],\n",
      "         [ 0,  0],\n",
      "         [ 0,  0]],\n",
      "\n",
      "        [[ 0,  4],\n",
      "         [ 0,  4],\n",
      "         [ 0,  4],\n",
      "         ...,\n",
      "         [ 0,  0],\n",
      "         [ 0,  0],\n",
      "         [ 0,  0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2, 42],\n",
      "         [ 2, 42],\n",
      "         [ 2, 42],\n",
      "         ...,\n",
      "         [ 2, 42],\n",
      "         [ 2, 42],\n",
      "         [ 2, 42]],\n",
      "\n",
      "        [[ 2, 48],\n",
      "         [ 2, 48],\n",
      "         [ 2, 48],\n",
      "         ...,\n",
      "         [ 2, 48],\n",
      "         [ 2, 48],\n",
      "         [ 2, 48]],\n",
      "\n",
      "        [[ 2, 49],\n",
      "         [ 2, 49],\n",
      "         [ 2, 49],\n",
      "         ...,\n",
      "         [ 2, 49],\n",
      "         [ 2, 49],\n",
      "         [ 2, 49]]]), 'encoder_cont': tensor([[[ 1.1111,  0.9645,  0.9599,  ...,  1.3726, -1.0556, -0.6921],\n",
      "         [ 1.1111,  0.9645,  0.9599,  ...,  1.3765, -1.0000, -0.6904],\n",
      "         [ 1.1111,  0.9645,  0.9599,  ...,  1.3804, -0.9444, -0.5769],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 1.0000,  1.1320,  1.1244,  ...,  1.3452, -1.0000, -0.8084],\n",
      "         [ 1.0000,  1.1320,  1.1244,  ...,  1.3492, -0.9444, -0.6605],\n",
      "         [ 1.0000,  1.1320,  1.1244,  ...,  1.3531, -0.8889, -0.8636],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 1.1111,  0.6096,  0.6899,  ...,  1.3726, -1.0556, -0.3837],\n",
      "         [ 1.1111,  0.6096,  0.6899,  ...,  1.3765, -1.0000, -0.6134],\n",
      "         [ 1.1111,  0.6096,  0.6899,  ...,  1.3804, -0.9444, -0.4967],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[14.0000, -0.8054, -0.8865,  ...,  1.3726, -7.5000, -0.0213],\n",
      "         [14.0000, -0.8054, -0.8865,  ...,  1.3726, -7.4444, -0.0213],\n",
      "         [14.0000, -0.8054, -0.8865,  ...,  1.3765, -7.3889,  0.2972],\n",
      "         ...,\n",
      "         [14.0000, -0.8054, -0.8865,  ...,  1.6303, -0.1667,  0.0621],\n",
      "         [14.0000, -0.8054, -0.8865,  ...,  1.6303, -0.1111,  0.0621],\n",
      "         [14.0000, -0.8054, -0.8865,  ...,  1.6342, -0.0556,  0.3510]],\n",
      "\n",
      "        [[14.0000, -0.8622, -0.8807,  ...,  1.3726, -7.5000,  0.1125],\n",
      "         [14.0000, -0.8622, -0.8807,  ...,  1.3726, -7.4444,  0.1125],\n",
      "         [14.0000, -0.8622, -0.8807,  ...,  1.3765, -7.3889,  0.4432],\n",
      "         ...,\n",
      "         [14.0000, -0.8622, -0.8807,  ...,  1.6303, -0.1667, -0.5999],\n",
      "         [14.0000, -0.8622, -0.8807,  ...,  1.6303, -0.1111, -0.5999],\n",
      "         [14.0000, -0.8622, -0.8807,  ...,  1.6342, -0.0556, -0.1379]],\n",
      "\n",
      "        [[14.0000, -0.8694, -0.8831,  ...,  1.3726, -7.5000,  0.4520],\n",
      "         [14.0000, -0.8694, -0.8831,  ...,  1.3726, -7.4444,  0.4520],\n",
      "         [14.0000, -0.8694, -0.8831,  ...,  1.3765, -7.3889,  0.4249],\n",
      "         ...,\n",
      "         [14.0000, -0.8694, -0.8831,  ...,  1.6303, -0.1667, -0.5422],\n",
      "         [14.0000, -0.8694, -0.8831,  ...,  1.6303, -0.1111, -0.5422],\n",
      "         [14.0000, -0.8694, -0.8831,  ...,  1.6342, -0.0556, -0.2389]]]), 'encoder_target': tensor([[33.5074, 33.6367, 42.4142,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [26.1250, 38.5000, 21.5000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [47.0942, 31.7067, 39.5270,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [15.8810, 15.8810, 17.9545,  ..., 16.4237, 16.4237, 18.3051],\n",
      "        [14.5000, 14.5000, 16.7273,  ...,  9.7018,  9.7018, 12.8136],\n",
      "        [16.4524, 16.4524, 16.2727,  ...,  9.8500,  9.8500, 11.8644]]), 'encoder_lengths': tensor([ 19,  18,  19,  18,  18,  17,  19,  19,  18,  18,  19,  16,  18,  19,\n",
      "         19,  19,  13,  18,  18,  18,  19,  18,  17,  18,  18,  18,  18,  18,\n",
      "         18,  18,  18,  13,  19,  18,  18,  19,  19,  18,  19,  19,  19,  19,\n",
      "         19,  18,  19,  19, 135, 135, 135, 135, 135, 135, 135]), 'decoder_cat': tensor([[[ 0,  1],\n",
      "         [ 0,  1],\n",
      "         [ 0,  1],\n",
      "         ...,\n",
      "         [ 0,  1],\n",
      "         [ 0,  1],\n",
      "         [ 0,  1]],\n",
      "\n",
      "        [[ 0,  3],\n",
      "         [ 0,  3],\n",
      "         [ 0,  3],\n",
      "         ...,\n",
      "         [ 0,  3],\n",
      "         [ 0,  3],\n",
      "         [ 0,  3]],\n",
      "\n",
      "        [[ 0,  4],\n",
      "         [ 0,  4],\n",
      "         [ 0,  4],\n",
      "         ...,\n",
      "         [ 0,  4],\n",
      "         [ 0,  4],\n",
      "         [ 0,  4]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2, 42],\n",
      "         [ 2, 42],\n",
      "         [ 2, 42],\n",
      "         ...,\n",
      "         [ 2, 42],\n",
      "         [ 2, 42],\n",
      "         [ 2, 42]],\n",
      "\n",
      "        [[ 2, 48],\n",
      "         [ 2, 48],\n",
      "         [ 2, 48],\n",
      "         ...,\n",
      "         [ 2, 48],\n",
      "         [ 2, 48],\n",
      "         [ 2, 48]],\n",
      "\n",
      "        [[ 2, 49],\n",
      "         [ 2, 49],\n",
      "         [ 2, 49],\n",
      "         ...,\n",
      "         [ 2, 49],\n",
      "         [ 2, 49],\n",
      "         [ 2, 49]]]), 'decoder_cont': tensor([[[ 1.1111,  0.9645,  0.9599,  ...,  1.4468,  0.0000, -0.7028],\n",
      "         [ 1.1111,  0.9645,  0.9599,  ...,  1.4507,  0.0556,  0.0636],\n",
      "         [ 1.1111,  0.9645,  0.9599,  ...,  1.4546,  0.1111, -0.1618],\n",
      "         ...,\n",
      "         [ 1.1111,  0.9645,  0.9599,  ...,  1.8217,  5.3889,  0.5589],\n",
      "         [ 1.1111,  0.9645,  0.9599,  ...,  1.8256,  5.4444,  1.5587],\n",
      "         [ 1.1111,  0.9645,  0.9599,  ...,  1.8295,  5.5000,  3.9575]],\n",
      "\n",
      "        [[ 1.0000,  1.1320,  1.1244,  ...,  1.4155,  0.0000, -0.3056],\n",
      "         [ 1.0000,  1.1320,  1.1244,  ...,  1.4194,  0.0556, -0.5803],\n",
      "         [ 1.0000,  1.1320,  1.1244,  ...,  1.4233,  0.1111, -0.6386],\n",
      "         ...,\n",
      "         [ 1.0000,  1.1320,  1.1244,  ...,  1.7943,  5.3889,  0.2178],\n",
      "         [ 1.0000,  1.1320,  1.1244,  ...,  1.7982,  5.4444,  0.2178],\n",
      "         [ 1.0000,  1.1320,  1.1244,  ...,  1.8021,  5.5000, -0.0272]],\n",
      "\n",
      "        [[ 1.1111,  0.6096,  0.6899,  ...,  1.4468,  0.0000, -0.5554],\n",
      "         [ 1.1111,  0.6096,  0.6899,  ...,  1.4507,  0.0556,  0.0685],\n",
      "         [ 1.1111,  0.6096,  0.6899,  ...,  1.4546,  0.1111, -0.1846],\n",
      "         ...,\n",
      "         [ 1.1111,  0.6096,  0.6899,  ...,  1.8217,  5.3889,  1.0056],\n",
      "         [ 1.1111,  0.6096,  0.6899,  ...,  1.8256,  5.4444,  1.8700],\n",
      "         [ 1.1111,  0.6096,  0.6899,  ...,  1.8295,  5.5000,  2.9115]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[14.0000, -0.8054, -0.8865,  ...,  1.6342,  0.0000,  0.3510],\n",
      "         [14.0000, -0.8054, -0.8865,  ...,  1.6381,  0.0556,  0.3742],\n",
      "         [14.0000, -0.8054, -0.8865,  ...,  1.6381,  0.1111,  0.3742],\n",
      "         ...,\n",
      "         [14.0000, -0.8054, -0.8865,  ...,  1.8256,  5.3889,  0.8691],\n",
      "         [14.0000, -0.8054, -0.8865,  ...,  1.8256,  5.4444,  0.8691],\n",
      "         [14.0000, -0.8054, -0.8865,  ...,  1.8295,  5.5000,  0.1308]],\n",
      "\n",
      "        [[14.0000, -0.8622, -0.8807,  ...,  1.6342,  0.0000, -0.1379],\n",
      "         [14.0000, -0.8622, -0.8807,  ...,  1.6381,  0.0556, -0.4983],\n",
      "         [14.0000, -0.8622, -0.8807,  ...,  1.6381,  0.1111, -0.4983],\n",
      "         ...,\n",
      "         [14.0000, -0.8622, -0.8807,  ...,  1.8256,  5.3889,  0.4546],\n",
      "         [14.0000, -0.8622, -0.8807,  ...,  1.8256,  5.4444,  0.4546],\n",
      "         [14.0000, -0.8622, -0.8807,  ...,  1.8295,  5.5000, -0.1748]],\n",
      "\n",
      "        [[14.0000, -0.8694, -0.8831,  ...,  1.6342,  0.0000, -0.2389],\n",
      "         [14.0000, -0.8694, -0.8831,  ...,  1.6381,  0.0556, -0.6675],\n",
      "         [14.0000, -0.8694, -0.8831,  ...,  1.6381,  0.1111, -0.6675],\n",
      "         ...,\n",
      "         [14.0000, -0.8694, -0.8831,  ...,  1.8256,  5.3889,  0.4161],\n",
      "         [14.0000, -0.8694, -0.8831,  ...,  1.8256,  5.4444,  0.4161],\n",
      "         [14.0000, -0.8694, -0.8831,  ...,  1.8295,  5.5000, -0.1432]]]), 'decoder_target': tensor([[ 32.6750,  91.9786,  74.5376,  ..., 130.2965, 207.6535, 393.2600],\n",
      "        [ 68.2000,  45.2143,  40.3333,  ..., 112.0000, 112.0000,  91.5000],\n",
      "        [ 35.5886,  77.3979,  60.4406,  ..., 140.2004, 198.1260, 267.9174],\n",
      "        ...,\n",
      "        [ 18.3051,  18.4561,  18.4561,  ...,  21.6786,  21.6786,  16.8710],\n",
      "        [ 12.8136,  10.3860,  10.3860,  ...,  16.8036,  16.8036,  12.5645],\n",
      "        [ 11.8644,   9.0175,   9.0175,  ...,  16.2143,  16.2143,  12.5000]]), 'decoder_lengths': tensor([100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "        100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]), 'decoder_time_idx': tensor([[ 962,  963,  964,  ..., 1059, 1060, 1061],\n",
      "        [ 954,  955,  956,  ..., 1051, 1052, 1053],\n",
      "        [ 962,  963,  964,  ..., 1059, 1060, 1061],\n",
      "        ...,\n",
      "        [1078, 1079, 1080,  ..., 1175, 1176, 1177],\n",
      "        [1078, 1079, 1080,  ..., 1175, 1176, 1177],\n",
      "        [1078, 1079, 1080,  ..., 1175, 1176, 1177]]), 'groups': tensor([[ 0,  1],\n",
      "        [ 0,  3],\n",
      "        [ 0,  4],\n",
      "        [ 0,  5],\n",
      "        [ 0,  6],\n",
      "        [ 0,  7],\n",
      "        [ 0,  9],\n",
      "        [ 0, 12],\n",
      "        [ 0, 13],\n",
      "        [ 0, 14],\n",
      "        [ 0, 15],\n",
      "        [ 0, 16],\n",
      "        [ 0, 17],\n",
      "        [ 0, 20],\n",
      "        [ 0, 23],\n",
      "        [ 0, 24],\n",
      "        [ 0, 25],\n",
      "        [ 0, 27],\n",
      "        [ 0, 28],\n",
      "        [ 0, 29],\n",
      "        [ 0, 31],\n",
      "        [ 0, 32],\n",
      "        [ 0, 33],\n",
      "        [ 0, 36],\n",
      "        [ 0, 38],\n",
      "        [ 0, 39],\n",
      "        [ 0, 40],\n",
      "        [ 0, 43],\n",
      "        [ 0, 44],\n",
      "        [ 0, 46],\n",
      "        [ 0, 50],\n",
      "        [ 0, 51],\n",
      "        [ 1,  2],\n",
      "        [ 1, 11],\n",
      "        [ 1, 18],\n",
      "        [ 1, 19],\n",
      "        [ 1, 21],\n",
      "        [ 1, 22],\n",
      "        [ 1, 26],\n",
      "        [ 1, 34],\n",
      "        [ 1, 37],\n",
      "        [ 1, 41],\n",
      "        [ 1, 45],\n",
      "        [ 1, 47],\n",
      "        [ 1, 52],\n",
      "        [ 1, 53],\n",
      "        [ 2,  0],\n",
      "        [ 2,  8],\n",
      "        [ 2, 10],\n",
      "        [ 2, 30],\n",
      "        [ 2, 42],\n",
      "        [ 2, 48],\n",
      "        [ 2, 49]]), 'target_scale': tensor([[ 88.0543,  77.3741],\n",
      "        [ 94.7764,  83.6878],\n",
      "        [ 73.8098,  67.0137],\n",
      "        [ 79.2078,  64.9164],\n",
      "        [ 80.1710,  76.3143],\n",
      "        [ 78.3413,  73.4079],\n",
      "        [ 88.5507,  76.5584],\n",
      "        [ 81.9276,  69.0506],\n",
      "        [ 94.7847,  84.4640],\n",
      "        [ 74.6819,  69.9355],\n",
      "        [ 77.6662,  67.9784],\n",
      "        [115.3682, 100.3422],\n",
      "        [ 97.2783,  86.1819],\n",
      "        [ 90.3083,  68.2144],\n",
      "        [123.0075, 132.4516],\n",
      "        [ 70.8473,  58.2521],\n",
      "        [102.8189,  90.0540],\n",
      "        [ 78.1777,  76.2012],\n",
      "        [100.2956,  87.0300],\n",
      "        [ 92.3483,  74.6194],\n",
      "        [ 77.3793,  68.5472],\n",
      "        [101.4687,  81.3797],\n",
      "        [ 95.0748,  89.5695],\n",
      "        [ 52.6284,  38.1400],\n",
      "        [114.2112,  99.3933],\n",
      "        [112.5398, 101.4486],\n",
      "        [ 90.8344,  84.7872],\n",
      "        [ 83.1749,  71.7847],\n",
      "        [106.9979,  86.0551],\n",
      "        [124.1206,  83.1005],\n",
      "        [ 85.2731,  78.8258],\n",
      "        [105.3054,  99.6135],\n",
      "        [ 11.3398,   6.1541],\n",
      "        [ 13.2511,   7.1977],\n",
      "        [ 16.1381,  10.8828],\n",
      "        [ 13.2665,   7.9471],\n",
      "        [ 14.8745,   7.5268],\n",
      "        [ 13.7133,   6.9512],\n",
      "        [ 14.3817,   7.2113],\n",
      "        [ 15.1076,   7.5063],\n",
      "        [ 10.1637,   6.0857],\n",
      "        [ 17.3396,  13.7520],\n",
      "        [ 11.3580,   5.2952],\n",
      "        [ 15.9426,   6.5941],\n",
      "        [ 14.2778,   9.1164],\n",
      "        [  7.5745,   4.3360],\n",
      "        [ 14.5831,   6.9816],\n",
      "        [ 15.2131,   7.5613],\n",
      "        [ 15.5047,   6.8648],\n",
      "        [ 15.7570,   6.5307],\n",
      "        [ 17.0195,   6.5117],\n",
      "        [ 14.7421,   6.7351],\n",
      "        [ 14.4508,   6.6411]])}, (tensor([[ 32.6750,  91.9786,  74.5376,  ..., 130.2965, 207.6535, 393.2600],\n",
      "        [ 68.2000,  45.2143,  40.3333,  ..., 112.0000, 112.0000,  91.5000],\n",
      "        [ 35.5886,  77.3979,  60.4406,  ..., 140.2004, 198.1260, 267.9174],\n",
      "        ...,\n",
      "        [ 18.3051,  18.4561,  18.4561,  ...,  21.6786,  21.6786,  16.8710],\n",
      "        [ 12.8136,  10.3860,  10.3860,  ...,  16.8036,  16.8036,  12.5645],\n",
      "        [ 11.8644,   9.0175,   9.0175,  ...,  16.2143,  16.2143,  12.5000]]), None))\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(val_dataloader):\n",
    "    print(i,j)#.data[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "68bdd5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tft.cpu().forward(j[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "83232503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "for i,j in res.items():\n",
    "    print(j.detach().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d25ab425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data[\"grid_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c3040c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set( data[lambda x: x.time_idx >= training_cutoff][\"grid_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d111218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "de7db02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5865bc54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j[0][\"groups\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e3800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f5bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c676712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
