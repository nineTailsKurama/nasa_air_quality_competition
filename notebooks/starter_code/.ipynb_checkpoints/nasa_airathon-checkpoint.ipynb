{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "38ecf21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(\"train_labels.csv\")\n",
    "grid_metadata = pd.read_csv(\"grid_metadata.csv\")\n",
    "satellite_metadata = pd.read_csv(\"satellite_metadata.csv\")\n",
    "satellite_metadata['Date'] =  pd.to_datetime(satellite_metadata['time_end'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ec24bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# REMOVE THIS LINE #\n",
    "####################\n",
    "train_labels = train_labels.sample(2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7ceeb22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_data(metadata, grid_id):\n",
    "    return metadata[metadata[\"grid_id\"] == grid_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6821e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_satellite_meta(metadata, datetime, location, datatype, split):\n",
    "    if location == \"Delhi\":\n",
    "        location = \"dl\"\n",
    "    elif location == \"Taipei\":\n",
    "        location = \"tpe\"\n",
    "    else:\n",
    "        location = \"la\"\n",
    "\n",
    "    metadata = metadata[metadata['location'] == location]\n",
    "    metadata = metadata[metadata['product'] == datatype]\n",
    "    metadata = metadata[metadata['split'] == split]\n",
    "    dateobject = parser.parse(datetime)\n",
    "    return metadata.loc[(metadata['Date'].dt.month == dateobject.month) & \n",
    "                        (metadata['Date'].dt.day == dateobject.day) &\n",
    "                        (metadata['Date'].dt.year <= dateobject.year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9212e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens the HDF file\n",
    "def load_data(FILEPATH):\n",
    "    ds = gdal.Open(FILEPATH)\n",
    "    return ds\n",
    "\n",
    "def fetch_subset(granule_id):\n",
    "    ds = load_data(\"dataset/\" + granule_id)\n",
    "    ds.GetSubDatasets()[0]\n",
    "    raster = gdal.Open(ds.GetSubDatasets()[8][0]) #grid5km:cosSZA features only\n",
    "    band = raster.GetRasterBand(1)\n",
    "    band_arr = band.ReadAsArray()\n",
    "    return band_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "52aa4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_training_features(grid_id, datetime, split):\n",
    "    temp = get_grid_data(grid_metadata, grid_id)\n",
    "    sat_met = fetch_satellite_meta(satellite_metadata, \n",
    "                               datetime, \n",
    "                               temp.iloc[0]['location'], \n",
    "                               \"maiac\", \n",
    "                               split)\n",
    "    counter = 0\n",
    "    features = None\n",
    "    for i in range(len(sat_met)):\n",
    "        counter+=1\n",
    "        granule_id = sat_met.iloc[i]['granule_id']\n",
    "        subset = fetch_subset(granule_id)\n",
    "        if features is None:\n",
    "            features = subset\n",
    "        else:\n",
    "            features+=subset\n",
    "    return features/counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6d270d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(train_labels, split):\n",
    "    labels = []\n",
    "    features = []\n",
    "    for i in range(len(train_labels)):\n",
    "        feature = fetch_training_features(train_labels.iloc[i]['grid_id'], train_labels.iloc[i]['datetime'], split)\n",
    "        features.append(np.array(feature).reshape(-1))\n",
    "        if split == \"train\":\n",
    "            labels.append(train_labels.iloc[i]['value'])\n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "56ce54d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = generate_features(train_labels, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5483a395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=10, batch_size=5, verbose=0)\n",
    "results = cross_val_score(estimator, features, labels)\n",
    "print(\"Baseline: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074956da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
